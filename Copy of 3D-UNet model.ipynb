{"cells":[{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18858,"status":"ok","timestamp":1690514768474,"user":{"displayName":"Zifeng Wang (George)","userId":"11537422646774520818"},"user_tz":-60},"id":"FrvaxBZsBYbu","outputId":"791cc134-ce89-46a8-f2cc-ac591f1536f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount(\"/content/gdrive\")"]},{"cell_type":"markdown","metadata":{"id":"6XRxHiKdGHiT"},"source":["# 3D-UNet reconstruction model"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Eq1KWmR3HWYV","executionInfo":{"status":"ok","timestamp":1690514456254,"user_tz":-60,"elapsed":8215,"user":{"displayName":"Zifeng Wang (George)","userId":"11537422646774520818"}}},"outputs":[],"source":["# Import libraries\n","import tarfile\n","import imageio\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset\n","import numpy as np\n","import time\n","import os\n","import random\n","import matplotlib.pyplot as plt\n","from matplotlib import colors\n","import imageio.v2 as imageio\n","\n","import nibabel as nib\n","from tqdm import tqdm\n","import glob\n","import shutil\n","import keras\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mt93oQ8xZkE9"},"outputs":[],"source":["# # Download the dataset\n","# !wget https://www.dropbox.com/s/zmytk2yu284af6t/Task01_BrainTumour_2D.tar.gz\n","\n","# # Unzip the '.tar.gz' file to the current directory\n","# datafile = tarfile.open('Task01_BrainTumour_2D.tar.gz')\n","# datafile.extractall()\n","# datafile.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Zqwh9Xh_6_Q"},"outputs":[],"source":["nii_file = '/Users/zifengwang/Desktop/Imperial_Computing/Indiv_Research/Code/Zhuang_dataset/labelled_meshes/ct_train_1010_label.nii.gz'\n","nii_image = nib.load(nii_file)\n","x, y, z = nii_image.shape\n","\n","# Extract the image data as a NumPy array\n","data = nii_image.get_fdata()\n","\n","# plt.imshow(img.get_fdata()[:, :, z//2], cmap='gray')\n","\n","lv_value = 500\n","rv_value = 600\n","la_value = 420\n","\n","lv_mask = (data == lv_value)\n","lv_center_of_mass = np.mean(np.nonzero(lv_mask), axis=1)\n","\n","rv_mask = (data == rv_value)\n","rv_center_of_mass = np.mean(np.nonzero(rv_mask), axis=1)\n","\n","la_mask = (data == la_value)\n","la_center_of_mass = np.mean(np.nonzero(la_mask), axis=1)\n","\n","\n","# Extract the 2-chamber and 4-chamber views\n","# Set  all non-2chamber and non-4-chamber views pixels as 0(background value)\n","data[0:int(lv_center_of_mass[0]), 0:int(lv_center_of_mass[1]), :] = 0\n","data[(int(lv_center_of_mass[0]) + 1) : x, 0: int(lv_center_of_mass[1]), :] = 0\n","data[0:int(lv_center_of_mass[0]), (int(lv_center_of_mass[1]) + 1) : y, :] = 0\n","data[(int(lv_center_of_mass[0]) + 1) : x, (int(lv_center_of_mass[1]) + 1) : y, : ] = 0\n","\n","\n","# Save the sliced long axis views as a NIfTI file\n","sliced_img = nib.Nifti1Image(data, img.affine)\n","output_file = 'demo/ct_train_1010_4ch.nii.gz'\n","nib.save(sliced_img, output_file)\n","\n","# vector1 = rv_center_of_mass - lv_center_of_mass\n","# vector2 = lv_center_of_mass - la_center_of_mass\n","# normal_vector = np.cross(vector1, vector2)\n","\n","# normalized_normal_vector = normal_vector / np.linalg.norm(normal_vector)\n","# D = -np.dot(normalized_normal_vector, lv_center_of_mass)\n","\n","# x_range = np.arange(0, 256, 1)\n","# y_range = np.arange(0, 256, 1)\n","# z_range = np.arange(0, 256, 1)\n","# X, Y, Z = np.meshgrid(x_range, y_range, z_range)\n","\n","# Z_plane = (-normalized_normal_vector[0] * X - normalized_normal_vector[1] * Y - D) / normalized_normal_vector[2]\n","\n","# # Create a new NIfTI image using Z_plane as data\n","# new_nii = nib.Nifti1Image(Z_plane, affine=None)\n","\n","# # Set the header information (optional)\n","# new_nii.header['pixdim'] = nii_image.header['pixdim']\n","# new_nii.header['qform_code'] = nii_image.header['qform_code']\n","# new_nii.header['sform_code'] = nii_image.header['sform_code']\n","# new_nii.header['quatern_b'] = nii_image.header['quatern_b']\n","# new_nii.header['quatern_c'] = nii_image.header['quatern_c']\n","# new_nii.header['quatern_d'] = nii_image.header['quatern_d']\n","# new_nii.header['qoffset_x'] = nii_image.header['qoffset_x']\n","# new_nii.header['qoffset_y'] = nii_image.header['qoffset_y']\n","# new_nii.header['qoffset_z'] = nii_image.header['qoffset_z']\n","# new_nii.header['srow_x'] = nii_image.header['srow_x']\n","# new_nii.header['srow_y'] = nii_image.header['srow_y']\n","# new_nii.header['srow_z'] = nii_image.header['srow_z']\n","\n","# # Save the NIfTI image to a new file\n","# output_file = 'demo/ct_train_1010_4ch.nii.gz'\n","# nib.save(new_nii, output_file)\n","\n","# Z_plane = Z_plane.squeeze()\n","# plt.imshow(Z_plane, cmap='gray', origin='lower')\n","# plt.xlabel('X')\n","# plt.ylabel('Y')\n","# plt.title('Slice Plane')\n","# plt.colorbar()\n","# plt.show()\n","\n","# lowest_z_index = np.argmin(np.nonzero(lv_mask), axis=None)\n","# lv_apex = np.unravel_index(lowest_z_index, lv_mask.shape)\n","# # print(\"Center of mass:\", center_of_mass)\n","# print(\"Apex:\", lv_apex)\n","# lv_mask.shape\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e2nQL3Wz_6_R"},"outputs":[],"source":["input_dir = 'Zhuang_dataset/labelled_meshes'\n","output_dir = 'sliced_long_axis_views'\n","\n","os.makedirs(output_dir, exist_ok=True)\n","\n","nii_files = glob.glob(os.path.join(input_dir, \"*.nii.gz\"))\n","\n","for nii_file in nii_files:\n","    # Load the NIfTI file\n","    img = nib.load(nii_file)\n","    x, y, z = img.shape\n","    affine = img.affine\n","\n","    data = img.get_fdata()\n","\n","    # Extract the 2-chamber and 4-chamber views\n","    four_chamber_view = data[ :, y//2, :]\n","    two_chamber_view = data[x//2, :, :]\n","\n","    # Update the affine matrix\n","    new_affine = np.copy(affine)\n","    new_affine[0, 0] //= img.header.get_zooms()[0]\n","    new_affine[1, 1] //= img.header.get_zooms()[1]\n","    new_affine[2, 2] //= img.header.get_zooms()[2]\n","\n","    # Create the output filenames\n","    file_name = os.path.basename(nii_file)\n","    two_chamber_filename = os.path.join(output_dir, \"2ch_\" + file_name)\n","    four_chamber_filename = os.path.join(output_dir, \"4ch_\" + file_name)\n","\n","    # Save the 2-chamber view as a NIfTI file\n","    two_chamber_img = nib.Nifti1Image(two_chamber_view, new_affine)\n","    nib.save(two_chamber_img, two_chamber_filename)\n","\n","    # Save the 4-chamber view as a NIfTI file\n","    four_chamber_img = nib.Nifti1Image(four_chamber_view, new_affine)\n","    nib.save(four_chamber_img, four_chamber_filename)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f3xv-cTm_6_S"},"outputs":[],"source":["input_dir_zhuang = 'Zhuang_dataset/labelled_meshes'\n","input_dir_bai = 'Bai_dataset/pilot_project/data/14*'\n","output_dir = '3D_long_axis_views_bai'\n","\n","os.makedirs(output_dir, exist_ok=True)\n","\n","nii_files = glob.glob(os.path.join(input_dir_bai, \"segmentation_*.nii.gz\"))\n","\n","for nii_file in nii_files:\n","    # Load the NIfTI file\n","    img = nib.load(nii_file)\n","    x, y, z, c = img.shape\n","\n","    data = img.get_fdata()\n","\n","    lv_value = 1\n","    rv_value = 4\n","\n","    lv_mask = (data == lv_value)\n","    lv_centre = np.mean(np.nonzero(lv_mask), axis=1)\n","\n","    # Extract the 2-chamber and 4-chamber views\n","    # Set all non-2chamber and non-4-chamber views pixels as 0(background value)\n","    data[0:int(lv_centre[0]), 0:int(lv_centre[1]), :] = 0\n","    data[(int(lv_centre[0]) + 1) : x, 0: int(lv_centre[1]), :] = 0\n","    data[0:int(lv_centre[0]), (int(lv_centre[1]) + 1) : y, :] = 0\n","    data[(int(lv_centre[0]) + 1) : x, (int(lv_centre[1]) + 1) : y, : ] = 0\n","\n","    #remove all cardiac structures other than left ventricle and left ventricle myocardium\n","    lv = [1,2]\n","    data = np.where(np.isin(data, lv), data, 0)\n","\n","    # Create the output filenames\n","    sample_name = os.path.basename(os.path.dirname(nii_file))\n","    sample_phase = os.path.basename(nii_file)\n","    sliced_filename = os.path.join(output_dir, sample_name + \"_\" + sample_phase)\n","\n","    # Save the sliced long axis views as a NIfTI file\n","    sliced_img = nib.Nifti1Image(data, img.affine)\n","    nib.save(sliced_img, sliced_filename)\n"]},{"cell_type":"markdown","metadata":{"id":"aFcys-pu_6_T"},"source":["# Move the nii.gz files from separate directories into the same directory"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gpBtuc7R_6_U"},"outputs":[],"source":["# import shutil\n","# #directory of 3D segmentation label files\n","# directory_path = 'Bai_dataset/pilot_project/data/14*'\n","# output_directory = '3D_label_views_bai'\n","\n","# if not os.path.exists(output_directory):\n","#     os.makedirs(output_directory)\n","\n","# # Iterate over the files in the directory\n","# for root, dirs, files in os.walk(directory_path):\n","#     for file_name in files:\n","#         if file_name.endswith('.nii.gz') and file_name.startswith('segmentation'):\n","#             img = nib.load(os.path.join(directory_path, file_name))\n","\n","#             data = img.get_fdata()\n","#             lv = [1,2]\n","#             data = np.where(np.isin(data, lv), data, 0)\n","\n","#             file_path = os.path.join(root, file_name)\n","#             new_file_name = os.path.basename(root) + '_' + file_name\n","#             new_file_path = os.path.join(output_directory, new_file_name)\n","#             # shutil.copyfile(file_path, new_file_path)\n","\n","#             # Save the views as a NIfTI file\n","#             processed_img = nib.Nifti1Image(data, img.affine)\n","#             nib.save(processed_img, new_file_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b4gnf2i2_6_V"},"outputs":[],"source":["input_dir_bai = 'Bai_dataset/pilot_project/data/14*'\n","output_dir = '3D_label_views_bai'\n","\n","os.makedirs(output_dir, exist_ok=True)\n","\n","nii_files = glob.glob(os.path.join(input_dir_bai, \"segmentation_*.nii.gz\"))\n","\n","for nii_file in nii_files:\n","    # Load the NIfTI file\n","    img = nib.load(nii_file)\n","    x, y, z, c = img.shape\n","\n","    data = img.get_fdata()\n","\n","    #remove all cardiac structures other than left ventricle and left ventricle myocardium\n","    lv = [1,2]\n","    data = np.where(np.isin(data, lv), data, 0)\n","\n","    # Create the output filenames\n","    sample_name = os.path.basename(os.path.dirname(nii_file))\n","    sample_phase = os.path.basename(nii_file)\n","    sliced_filename = os.path.join(output_dir, sample_name + \"_\" + sample_phase)\n","\n","    # Save the sliced long axis views as a NIfTI file\n","    sliced_img = nib.Nifti1Image(data, img.affine)\n","    nib.save(sliced_img, sliced_filename)\n"]},{"cell_type":"markdown","metadata":{"id":"jUfqu6og_6_W"},"source":["# Apply padding to original samples to unify sample shapes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LGIKwZ2I_6_X","outputId":"76db564a-94c3-4445-c8ec-d87350a32c53"},"outputs":[{"name":"stdout","output_type":"stream","text":["(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n","(320, 320, 60, 1)\n"]}],"source":["import math\n","\n","input_dir_bai = '3D_label_views_bai'\n","output_dir = 'pad_3D_label_views_bai'\n","\n","os.makedirs(output_dir, exist_ok=True)\n","\n","nii_files = glob.glob(os.path.join(input_dir_bai, \"*.nii.gz\"))\n","\n","max_x = max_y = max_z = 0\n","\n","#identify the largest shape in the training samples\n","for nii_file in nii_files:\n","    # Load the NIfTI file\n","    img = nib.load(nii_file)\n","    x1, y1, z1, c1 = img.shape\n","    if x1 > max_x:\n","        max_x = x1\n","    if y1 > max_y:\n","        max_y = y1\n","    if z1 > max_z:\n","        max_z = z1\n","\n","for nii_file in nii_files:\n","    img = nib.load(nii_file)\n","    x, y, z, c = img.shape\n","    data = img.get_fdata()\n","\n","    pad_x = int((max_x - x)/2)\n","    pad_y = int((max_y - y)/2)\n","    pad_z_left = (max_z - z)//2\n","    pad_z_right = math.ceil((max_z - z) / 2)\n","\n","    padded_data = np.pad(data, pad_width=((pad_x,pad_x), (pad_y, pad_y), (pad_z_left, pad_z_right), (0,0)))\n","\n","#     print(padded_data.shape)\n","\n","    # Create the output filenames\n","    sample_name = os.path.basename(nii_file)\n","    padded_filename = os.path.join(output_dir, \"pad_\" + sample_name)\n","\n","    # Save the sliced long axis views as a NIfTI file\n","    padded_img = nib.Nifti1Image(padded_data, img.affine)\n","    nib.save(padded_img, padded_filename)"]},{"cell_type":"markdown","metadata":{"id":"axgF2run_6_Y"},"source":["# Apply padding to long-axis views"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"618l18o0_6_Z"},"outputs":[],"source":["import math\n","\n","input_dir_bai = '3D_long_axis_views_bai'\n","output_dir = 'pad_3D_long_axis_views_bai'\n","\n","os.makedirs(output_dir, exist_ok=True)\n","\n","nii_files = glob.glob(os.path.join(input_dir_bai, \"*.nii.gz\"))\n","\n","max_x = max_y = max_z = 0\n","\n","#identify the largest shape in the training samples\n","for nii_file in nii_files:\n","    # Load the NIfTI file\n","    img = nib.load(nii_file)\n","    x1, y1, z1, c1 = img.shape\n","    if x1 > max_x:\n","        max_x = x1\n","    if y1 > max_y:\n","        max_y = y1\n","    if z1 > max_z:\n","        max_z = z1\n","\n","#apply padding to the images and save the padded images to output_dir\n","for nii_file in nii_files:\n","    img = nib.load(nii_file)\n","    x, y, z, c = img.shape\n","    data = img.get_fdata()\n","\n","    pad_x = int((max_x - x)/2)\n","    pad_y = int((max_y - y)/2)\n","    pad_z_left = (max_z - z)//2\n","    pad_z_right = math.ceil((max_z - z) / 2)\n","\n","    padded_data = np.pad(data, pad_width=((pad_x,pad_x), (pad_y, pad_y), (pad_z_left, pad_z_right), (0,0)))\n","\n","    # Create the output filenames\n","    sample_name = os.path.basename(nii_file)\n","    padded_filename = os.path.join(output_dir, \"pad_\" + sample_name)\n","\n","    # Save the sliced long axis views as a NIfTI file\n","    padded_img = nib.Nifti1Image(padded_data, img.affine)\n","    nib.save(padded_img, padded_filename)"]},{"cell_type":"markdown","metadata":{"id":"PuUV2rHn_6_Z"},"source":["# Apply cropping to original images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eWCPQoJa_6_a"},"outputs":[],"source":["#function that takes a numpy array and output a cropped array\n","def crop_center_of_mass(array, centre_label = 1):\n","    # Find the center of mass of the structure with label 1\n","    indices = np.argwhere(array == centre_label)\n","    center_of_mass = np.mean(indices, axis=0)\n","\n","    # Calculate the crop boundaries\n","    x_start = int(center_of_mass[0] - 64)\n","    x_end = x_start + 128\n","    y_start = int(center_of_mass[1] - 64)\n","    y_end = y_start + 128\n","\n","    # Crop the array around the center of mass\n","    cropped_array = array[x_start:x_end, y_start:y_end, :, :]\n","\n","    return cropped_array\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yFUZuUw7_6_a"},"outputs":[],"source":["import math\n","input_dir_bai = '3D_long_axis_views_bai'\n","output_dir = 'crop_3D_long_axis_views_bai'\n","\n","os.makedirs(output_dir, exist_ok=True)\n","\n","nii_files = glob.glob(os.path.join(input_dir_bai, \"*.nii.gz\"))\n","\n","#apply cropping to the images and save the cropped images to output_dir\n","for nii_file in nii_files:\n","    img = nib.load(nii_file)\n","    x, y, z, c = img.shape\n","    data = img.get_fdata()\n","\n","    data = crop_center_of_mass(data, centre_label = 1)\n","\n","    pad_z_left = (64 - z)//2\n","    pad_z_right = math.ceil((64 - z) / 2)\n","    data = np.pad(data, pad_width=((0,0), (0,0), (pad_z_left, pad_z_right), (0,0)))\n","\n","    # Create the output filenames\n","    sample_name = os.path.basename(nii_file)\n","    cropped_filename = os.path.join(output_dir, \"crop_\" + sample_name)\n","\n","    # Save the sliced long axis views as a NIfTI file\n","    cropped_img = nib.Nifti1Image(data, img.affine)\n","    nib.save(cropped_img, cropped_filename)\n","\n","\n","input_dir_bai = '3D_label_views_bai'\n","output_dir = 'crop_3D_label_views_bai'\n","\n","os.makedirs(output_dir, exist_ok=True)\n","\n","nii_files = glob.glob(os.path.join(input_dir_bai, \"*.nii.gz\"))\n","\n","#apply cropping to the images and save the cropped images to output_dir\n","for nii_file in nii_files:\n","    img = nib.load(nii_file)\n","    x, y, z, c = img.shape\n","    data = img.get_fdata()\n","\n","    data = crop_center_of_mass(data, centre_label = 1)\n","\n","    pad_z_left = (64 - z)//2\n","    pad_z_right = math.ceil((64 - z) / 2)\n","    data = np.pad(data, pad_width=((0,0), (0,0), (pad_z_left, pad_z_right), (0,0)))\n","\n","    # Create the output filenames\n","    sample_name = os.path.basename(nii_file)\n","    cropped_filename = os.path.join(output_dir, \"crop_\" + sample_name)\n","\n","    # Save the sliced long axis views as a NIfTI file\n","    cropped_img = nib.Nifti1Image(data, img.affine)\n","    nib.save(cropped_img, cropped_filename)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eE6lrbsp_6_b","outputId":"934ef397-eff0-4b0e-8e13-78073bd3e49f"},"outputs":[{"name":"stdout","output_type":"stream","text":["(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n"]}],"source":["output_dir = 'crop_3D_label_views_bai'\n","nii_files = glob.glob(os.path.join(output_dir, \"*.nii.gz\"))\n","for nii_file in nii_files:\n","    img = nib.load(nii_file)\n","    data = img.get_fdata()\n","    print(data.shape)"]},{"cell_type":"markdown","metadata":{"id":"VVNys25v_6_b"},"source":["# Separate data into training set and test set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"35zNup_L_6_c"},"outputs":[],"source":["import os\n","import random\n","import shutil\n","\n","# Set the paths to the original image and label folders\n","image_folder = 'crop_3D_long_axis_views_bai'\n","label_folder = 'crop_3D_label_views_bai'\n","\n","# Set the paths to the train and test folders\n","train_image_folder = 'crop_preprocessed_bai/train_2D'\n","train_label_folder = 'crop_preprocessed_bai/train_3D'\n","test_image_folder = 'crop_preprocessed_bai/test_2D'\n","test_label_folder = 'crop_preprocessed_bai/test_3D'\n","\n","# Create the train and test folders if they don't exist\n","os.makedirs(train_image_folder, exist_ok=True)\n","os.makedirs(train_label_folder, exist_ok=True)\n","os.makedirs(test_image_folder, exist_ok=True)\n","os.makedirs(test_label_folder, exist_ok=True)\n","\n","# Get the list of image files in the image folder\n","image_files = [file for file in os.listdir(image_folder) if file.endswith('.nii.gz')]\n","\n","# Shuffle the image files randomly\n","random.shuffle(image_files)\n","\n","# Calculate the number of files for training and testing\n","train_ratio = 0.8\n","num_train = int(len(image_files) * train_ratio)\n","num_test = len(image_files) - num_train\n","\n","# Split the image files into train and test sets\n","train_images = image_files[:num_train]\n","test_images = image_files[num_train:]\n","\n","# Move the images and labels to the respective train and test folders\n","for image in train_images:\n","    src_image_path = os.path.join(image_folder, image)\n","    dst_image_path = os.path.join(train_image_folder, image)\n","    shutil.move(src_image_path, dst_image_path)\n","\n","    # Move the corresponding label file\n","    label_file = os.path.basename(image)\n","    src_label_path = os.path.join(label_folder, label_file)\n","    dst_label_path = os.path.join(train_label_folder, label_file)\n","    shutil.move(src_label_path, dst_label_path)\n","\n","for image in test_images:\n","    src_image_path = os.path.join(image_folder, image)\n","    dst_image_path = os.path.join(test_image_folder, image)\n","    shutil.move(src_image_path, dst_image_path)\n","\n","    # Move the corresponding label file\n","    label_file = os.path.basename(image)\n","    src_label_path = os.path.join(label_folder, label_file)\n","    dst_label_path = os.path.join(test_label_folder, label_file)\n","    shutil.move(src_label_path, dst_label_path)\n"]},{"cell_type":"markdown","metadata":{"id":"5xWGT3KaML-D"},"source":["## 2. Implement a dataset class.\n","\n","It can read the imaging dataset and get items, pairs of images and label maps, as training batches."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6p6wFZ3na5z9"},"outputs":[],"source":["class CardiacImageSet(keras.utils.Sequence):\n","    \"\"\" Cardiac image set \"\"\"\n","    def __init__(self, image_path, label_path='', deploy=False):\n","        self.image_path = image_path\n","        self.deploy = deploy\n","        self.images = []\n","        self.labels = []\n","\n","        image_names = [file for file in os.listdir(image_path) if file.endswith('.nii.gz')]\n","        for image_name in image_names:\n","            # Read the image\n","            image = nib.load(os.path.join(image_path, image_name))\n","            image = image.get_fdata()\n","            #transpose image dimension from XYZC to CXYZ\n","            image = np.transpose(image, (3, 0, 1, 2))\n","            self.images += [image]\n","\n","            # Read the label map\n","            if not self.deploy:\n","                label_name = os.path.join(label_path, image_name)\n","                label = nib.load(label_name)\n","                label = label.get_fdata()\n","                label = np.transpose(label, (3, 0, 1, 2))\n","                self.labels += [label]\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        # Get an image and perform intensity normalisation\n","        # Dimension: XYZ\n","        # image = normalise_intensity(self.images[idx])\n","        image = self.images[idx]\n","\n","        # Get its label map\n","        # Dimension: XYZ\n","        label = self.labels[idx]\n","        return image, label\n","\n","    def get_random_batch(self, batch_size):\n","        # Get a batch of paired images and label maps\n","        # Dimension of images: NCXYZ\n","        # Dimension of labels: NXYZ\n","        images, labels = [], []\n","\n","        ### Insert your code ###\n","        for i in range(batch_size):\n","            #randomly retrieve an image and label map\n","            random_idx = random.randint(0,self.__len__() - 1)\n","            random_image, random_label = self.__getitem__(random_idx)\n","            images += [random_image]\n","            labels += [random_label]\n","\n","        #Turn the list into np array\n","        images = np.array(images)\n","        labels = np.array(labels)\n","        ### End of your code ###\n","        return images, labels\n","\n","    def get_batch(self, batch_size, iteration_num):\n","      images, labels = [], []\n","      batch_num = self.__len__()//batch_size\n","      image_idx = ((iteration_num % batch_num) - 1) * batch_size\n","      for i in range(batch_size):\n","        image, label = self.__getitem__(image_idx + i)\n","        images += [image]\n","        labels += [label]\n","\n","      images = np.array(images)\n","      labels = np.array(labels)\n","      return images, labels\n","\n","# train_set = CardiacImageSet('/content/gdrive/My Drive/crop_preprocessed_bai/train_2D', '/content/gdrive/My Drive/crop_preprocessed_bai/train_3D')\n","# test_set = CardiacImageSet('/content/gdrive/My Drive/crop_preprocessed_bai/test_2D', '/content/gdrive/My Drive/crop_preprocessed_bai/test_3D')\n","\n","# image_1, label_1 = train_set.__getitem__(88)\n","# print(image_1.shape)\n","# print(label_1.shape)\n","\n","# test_images, test_labels = train_set.get_random_batch(4)\n","# print(test_images.shape)\n","# print(test_labels.shape)\n","# print(test_images.dtype)\n"]},{"cell_type":"markdown","metadata":{"id":"pa4ZpawDNmwu"},"source":["## Construct a U-net architecture.\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"IMPmBZVGb1aI","executionInfo":{"status":"ok","timestamp":1690514472209,"user_tz":-60,"elapsed":309,"user":{"displayName":"Zifeng Wang (George)","userId":"11537422646774520818"}}},"outputs":[],"source":["class UNet3d(nn.Module):\n","    def contracting_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n","        block = torch.nn.Sequential(\n","            torch.nn.Conv3d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=1),\n","            torch.nn.LeakyReLU(0.1),\n","            torch.nn.BatchNorm3d(mid_channel),\n","            torch.nn.Conv3d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=out_channels, padding=1),\n","            torch.nn.LeakyReLU(0.1),\n","            torch.nn.BatchNorm3d(out_channels),\n","        )\n","        return block\n","\n","    def expansive_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n","        block = torch.nn.Sequential(\n","            torch.nn.Conv3d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=1),\n","            torch.nn.LeakyReLU(0.1),\n","            torch.nn.BatchNorm3d(mid_channel),\n","            torch.nn.Conv3d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel, padding=1),\n","            torch.nn.LeakyReLU(0.1),\n","            torch.nn.BatchNorm3d(mid_channel),\n","            torch.nn.ConvTranspose3d(in_channels=mid_channel, out_channels=out_channels, kernel_size=3, stride=2,\n","                                     padding=1, output_padding=1)\n","        )\n","        return block\n","\n","    def final_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n","        block = torch.nn.Sequential(\n","            torch.nn.Conv3d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=1),\n","            torch.nn.LeakyReLU(0.1),\n","            torch.nn.BatchNorm3d(mid_channel),\n","            torch.nn.Conv3d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel, padding=1),\n","            torch.nn.LeakyReLU(0.1),\n","            torch.nn.BatchNorm3d(mid_channel),\n","            torch.nn.Conv3d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=out_channels, padding=1),\n","            torch.nn.Sigmoid()\n","        )\n","        return block\n","\n","    def __init__(self, in_channel, out_channel):\n","        super(UNet3d, self).__init__()\n","        # Encode\n","        self.conv_encode1 = self.contracting_block(in_channel, 16, 32)\n","        self.conv_maxpool1 = torch.nn.MaxPool3d(kernel_size=2)\n","        self.conv_encode2 = self.contracting_block(32, 32, 64)\n","        self.conv_maxpool2 = torch.nn.MaxPool3d(kernel_size=2)\n","        self.conv_encode3 = self.contracting_block(64, 64, 128)\n","        self.conv_maxpool3 = torch.nn.MaxPool3d(kernel_size=2)\n","        # Bottleneck\n","        self.bottleneck = torch.nn.Sequential(\n","            torch.nn.Conv3d(kernel_size=3, in_channels=128, out_channels=128, padding=1),\n","            torch.nn.LeakyReLU(0.1),\n","            torch.nn.BatchNorm3d(128),\n","            torch.nn.Conv3d(kernel_size=3, in_channels=128, out_channels=256, padding=1),\n","            torch.nn.LeakyReLU(0.1),\n","            torch.nn.BatchNorm3d(256),\n","            torch.nn.ConvTranspose3d(in_channels=256, out_channels=256, kernel_size=3, stride=2, padding=1,\n","                                     output_padding=1)\n","        )\n","        # Decode\n","        self.conv_decode3 = self.expansive_block(128+256, 128, 128)\n","        self.conv_decode2 = self.expansive_block(64+128, 64, 64)\n","        self.final_layer = self.final_block(32+64, 32, out_channel)\n","\n","    def crop_and_concat(self, upsampled, bypass, crop=False):\n","        if crop:\n","            c = (bypass.size()[2] - upsampled.size()[2]) // 2\n","            bypass = F.pad(bypass, (-c, -c, -c, -c))\n","        # print(\"unsampled shape:\", upsampled.shape)\n","        # print(\"bypass shape:\", bypass.shape)\n","\n","        return torch.cat((upsampled, bypass), 1)\n","\n","    def forward(self, x):\n","        # Encode\n","        encode_block1 = self.conv_encode1(x)\n","        encode_pool1 = self.conv_maxpool1(encode_block1)\n","        encode_block2 = self.conv_encode2(encode_pool1)\n","        encode_pool2 = self.conv_maxpool2(encode_block2)\n","        encode_block3 = self.conv_encode3(encode_pool2)\n","        encode_pool3 = self.conv_maxpool3(encode_block3)\n","        # Bottleneck\n","        bottleneck1 = self.bottleneck(encode_pool3)\n","        # Decode\n","        decode_block3 = self.crop_and_concat(bottleneck1, encode_block3, crop=False)\n","        cat_layer2 = self.conv_decode3(decode_block3)\n","        decode_block2 = self.crop_and_concat(cat_layer2, encode_block2, crop=False)\n","        cat_layer1 = self.conv_decode2(decode_block2)\n","        decode_block1 = self.crop_and_concat(cat_layer1, encode_block1, crop=False)\n","        final_layer = self.final_layer(decode_block1)\n","        return final_layer\n"]},{"cell_type":"markdown","metadata":{"id":"NcNWZS08d47P"},"source":["## 4. Train the segmentation model."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xaGGkKQndIaR","outputId":"1dde7da5-fb1b-4348-ff37-b700f1bac5bc","executionInfo":{"status":"ok","timestamp":1690404330560,"user_tz":-60,"elapsed":484787,"user":{"displayName":"Zifeng Wang (George)","userId":"11537422646774520818"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cuda\n","training loss for epoch 1.0:\n","0.6309710741043091\n","test loss for iteration 1.0:\n","0.5744005441665649\n","training loss for epoch 2.0:\n","0.5774275064468384\n","test loss for iteration 2.0:\n","0.5718958377838135\n","training loss for epoch 3.0:\n","0.573948085308075\n","test loss for iteration 3.0:\n","0.5708145499229431\n","training loss for epoch 4.0:\n","0.5708648562431335\n","test loss for iteration 4.0:\n","0.8764143586158752\n","training loss for epoch 5.0:\n","0.5693016052246094\n","test loss for iteration 5.0:\n","0.5715335607528687\n","training loss for epoch 6.0:\n","0.5685228109359741\n","test loss for iteration 6.0:\n","1.1640300750732422\n","Training took 1464.462s in total.\n"]}],"source":["# CUDA device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Device: {0}'.format(device))\n","\n","# Build the model\n","num_class = 3\n","model = UNet3d(in_channel=1, out_channel=num_class)\n","model = model.to(device)\n","params = list(model.parameters())\n","\n","model_dir = '/content/gdrive/My Drive/saved_model'\n","if not os.path.exists(model_dir):\n","    os.makedirs(model_dir)\n","\n","# Optimizer\n","optimizer = optim.Adam(params, lr=1e-3)\n","\n","# Segmentation loss\n","criterion = nn.CrossEntropyLoss()\n","\n","train_image_folder = '/content/gdrive/My Drive/crop_preprocessed_bai/train_2D'\n","train_label_folder = '/content/gdrive/My Drive/crop_preprocessed_bai/train_3D'\n","test_image_folder = '/content/gdrive/My Drive/crop_preprocessed_bai/test_2D'\n","test_label_folder = '/content/gdrive/My Drive/crop_preprocessed_bai/test_3D'\n","\n","# Datasets\n","train_set = CardiacImageSet(train_image_folder, train_label_folder)\n","test_set = CardiacImageSet(test_image_folder, test_label_folder)\n","\n","# Train the model\n","\n","num_iter = 500\n","train_batch_size = 4\n","eval_batch_size = 4\n","start = time.time()\n","running_loss = 0\n","#number of batches in an epoch\n","num_batches = train_set.__len__()/train_batch_size\n","for it in range(1, 1 + num_iter):\n","    # Set the modules in training mode, which will have effects on certain modules, e.g. dropout or batchnorm.\n","    start_iter = time.time()\n","    model.train()\n","\n","    # Get a batch of images and labels\n","    images, labels = train_set.get_batch(train_batch_size, it)\n","    images, labels = torch.from_numpy(images), torch.from_numpy(labels)\n","    # image.to() convert the array from system RAM to GPU RAM\n","    images, labels = images.to(device, dtype=torch.float32), labels.to(device, dtype=torch.long)\n","    #remove the channel dimension in the labels array\n","    labels = labels.squeeze(axis = 1)\n","    # print(\"Images shape:\", images.shape)\n","    logits = model(images)\n","\n","    # Perform optimisation and print out the training loss\n","    # print('logits shape:', logits.shape)\n","    # print('label shape:', labels.shape)\n","\n","    loss = criterion(logits, labels)\n","    running_loss += loss\n","\n","    if it % num_batches == 0:\n","        epoch_loss = running_loss/num_batches\n","        running_loss = 0\n","        print (\"training loss for epoch {}:\".format(it/num_batches))\n","        print(epoch_loss.item())\n","\n","    loss.backward()\n","    optimizer.step()\n","    optimizer.zero_grad()\n","\n","    ###   ###\n","\n","    # Evaluate\n","    if it % num_batches == 0:\n","        model.eval()\n","        # Disabling gradient calculation during reference to reduce memory consumption\n","        with torch.no_grad():\n","            # Evaluate on a batch of test images and print out the test loss\n","            ### Insert your code ###\n","            test_images, test_labels = test_set.get_random_batch(eval_batch_size)\n","            test_images, test_labels = torch.from_numpy(test_images), torch.from_numpy(test_labels)\n","            test_images, test_labels = test_images.to(device, dtype=torch.float32), test_labels.to(device, dtype=torch.long)\n","            test_labels = test_labels.squeeze(axis = 1)\n","            test_logits = model(test_images)\n","            test_loss = criterion(test_logits, test_labels)\n","            print (\"test loss for iteration {}:\".format(it/num_batches))\n","            print(test_loss.item())\n","            ### End of your code ###\n","\n","    # Save the model\n","    if it % 100 == 0:\n","        torch.save(model.state_dict(), os.path.join(model_dir, 'model_{0}.pt'.format(it)))\n","print('Training took {:.3f}s in total.'.format(time.time() - start))"]},{"cell_type":"markdown","source":["# Visualise model reconstruction output"],"metadata":{"id":"_9l7P_WeFmcT"}},{"cell_type":"code","source":["device = torch.device(\"cpu\")\n","def model_load():\n","\n","    unet = UNet3d(in_channel=1, out_channel=3)\n","    unet.to(device, dtype=torch.float)\n","\n","    model_list = ['/content/gdrive/My Drive/saved_model/model_500.pt']\n","    model_i = model_list[0]\n","    checkpoint = torch.load(model_i)\n","    unet.load_state_dict(checkpoint)\n","    return unet\n","\n","def mr_lax_inference(unet, slice_img):\n","\n","    img = nib.load(slice_img)\n","    affine = img.affine\n","    data = img.get_fdata()\n","\n","    data = torch.from_numpy(data)\n","\n","    print(data.size())\n","\n","    data = np.transpose(data, (3, 0, 1, 2))\n","    data = data.to(device, dtype=torch.float32)\n","    data = np.expand_dims(data, axis=(0,1))\n","    unet.eval()\n","    output = unet(data)\n","    pred = output.detach().cpu().numpy()\n","\n","    return pred\n","\n","sliced_image = '/content/gdrive/My Drive/crop_preprocessed_bai/test_2D/crop_14AB01345_segmentation_ES.nii.gz'\n","unet = model_load()\n","pred = mr_lax_inference(unet, sliced_image)\n","pred_save_dir = '/content/gdrive/My Drive/pred_output/pred.nii.gz'\n","nib.save(pred, pred_save_dir)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"rOAr9DR4FlNg","executionInfo":{"status":"error","timestamp":1690516421113,"user_tz":-60,"elapsed":599,"user":{"displayName":"Zifeng Wang (George)","userId":"11537422646774520818"}},"outputId":"75ad3707-3481-439d-a091-25c007e4934b"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([128, 128, 64, 1])\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-a50dc08a2125>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0msliced_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/gdrive/My Drive/crop_preprocessed_bai/test_2D/crop_14AB01345_segmentation_ES.nii.gz'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0munet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmr_lax_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msliced_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mpred_save_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/gdrive/My Drive/pred_output/pred.nii.gz'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_save_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-a50dc08a2125>\u001b[0m in \u001b[0;36mmr_lax_inference\u001b[0;34m(unet, slice_img)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0munet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-42ec515de578>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# Encode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mencode_block1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_encode1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mencode_pool1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_maxpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencode_block1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mencode_block2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_encode2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencode_pool1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             )\n\u001b[0;32m--> 608\u001b[0;31m         return F.conv3d(\n\u001b[0m\u001b[1;32m    609\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m         )\n","\u001b[0;31mTypeError\u001b[0m: conv3d() received an invalid combination of arguments - got (numpy.ndarray, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!numpy.ndarray!, !Parameter!, !Parameter!, !tuple of (int, int, int)!, !tuple of (int, int, int)!, !tuple of (int, int, int)!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!numpy.ndarray!, !Parameter!, !Parameter!, !tuple of (int, int, int)!, !tuple of (int, int, int)!, !tuple of (int, int, int)!, int)\n"]}]},{"cell_type":"markdown","metadata":{"id":"89yjxjGyb6yT"},"source":["*italicised text*## 5. Deploy the trained model to a random set of 4 test images and visualise the automated segmentation.\n","\n","You can show the images as a 4 x 3 panel. Each row shows one example, with the 3 columns being the test image, automated segmentation and ground truth segmentation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wZeLE0qZjd2j"},"outputs":[],"source":["### Insert your code ###\n","image_test_1 = imageio.imread('Task01_BrainTumour_2D/test_images/BRATS_004_z62.png')\n","image_test_2 = imageio.imread('Task01_BrainTumour_2D/test_images/BRATS_016_z62.png')\n","image_test_3 = imageio.imread('Task01_BrainTumour_2D/test_images/BRATS_058_z93.png')\n","image_test_4 = imageio.imread('Task01_BrainTumour_2D/test_images/BRATS_115_z62.png')\n","\n","label_test_1 = imageio.imread('Task01_BrainTumour_2D/test_labels/BRATS_004_z62.png')\n","label_test_2 = imageio.imread('Task01_BrainTumour_2D/test_labels/BRATS_016_z62.png')\n","label_test_3 = imageio.imread('Task01_BrainTumour_2D/test_labels/BRATS_058_z93.png')\n","label_test_4 = imageio.imread('Task01_BrainTumour_2D/test_labels/BRATS_115_z62.png')\n","\n","image_test_1_3D, image_test_2_3D, image_test_3_3D, image_test_4_3D = np.expand_dims(image_test_1, axis=(0,1)), np.expand_dims(image_test_2, axis=(0,1)), np.expand_dims(image_test_3, axis=(0,1)), np.expand_dims(image_test_4, axis=(0,1))\n","image_test_1_tor, image_test_2_tor, image_test_3_tor, image_test_4_tor = torch.from_numpy(image_test_1_3D), torch.from_numpy(image_test_2_3D), torch.from_numpy(image_test_3_3D), torch.from_numpy(image_test_4_3D)\n","image_test_1_tor, image_test_2_tor, image_test_3_tor, image_test_4_tor = image_test_1_tor.to(device, dtype=torch.float32), image_test_2_tor.to(device, dtype=torch.float32), image_test_3_tor.to(device, dtype=torch.float32), image_test_4_tor.to(device, dtype=torch.float32)\n","\n","pred_test_1 = np.argmax((model(image_test_1_tor).detach().reshape((4,120,120))), 0)\n","pred_test_2 = np.argmax((model(image_test_2_tor).detach().reshape((4,120,120))), 0)\n","pred_test_3 = np.argmax((model(image_test_3_tor).detach().reshape((4,120,120))), 0)\n","pred_test_4 = np.argmax((model(image_test_4_tor).detach().reshape((4,120,120))), 0)\n","\n","fig = plt.figure(figsize=(50, 50))\n","\n","fig.add_subplot(4, 3, 1)\n","plt.imshow(image_test_1, cmap='gray')\n","plt.axis('off')\n","plt.gcf().set_size_inches(10, 10)\n","\n","fig.add_subplot(4, 3, 2)\n","plt.imshow(pred_test_1, cmap = colors.ListedColormap(['black', 'green', 'blue', 'red']))\n","plt.axis('off')\n","plt.gcf().set_size_inches(10, 10)\n","\n","fig.add_subplot(4, 3, 3)\n","plt.imshow(label_test_1, cmap = colors.ListedColormap(['black', 'green', 'blue', 'red']))\n","plt.axis('off')\n","plt.gcf().set_size_inches(10, 10)\n","\n","\n","fig.add_subplot(4, 3, 4)\n","plt.imshow(image_test_2, cmap='gray')\n","plt.axis('off')\n","plt.gcf().set_size_inches(10, 10)\n","\n","fig.add_subplot(4, 3, 5)\n","plt.imshow(pred_test_2, cmap = colors.ListedColormap(['black', 'green', 'blue', 'red']))\n","plt.axis('off')\n","plt.gcf().set_size_inches(10, 10)\n","\n","fig.add_subplot(4, 3, 6)\n","plt.imshow(label_test_2, cmap = colors.ListedColormap(['black', 'green', 'blue', 'red']))\n","plt.axis('off')\n","plt.gcf().set_size_inches(10, 10)\n","\n","\n","fig.add_subplot(4, 3, 7)\n","plt.imshow(image_test_3, cmap='gray')\n","plt.axis('off')\n","plt.gcf().set_size_inches(10, 10)\n","\n","fig.add_subplot(4, 3, 8)\n","plt.imshow(pred_test_3, cmap = colors.ListedColormap(['black', 'green', 'blue', 'red']))\n","plt.axis('off')\n","plt.gcf().set_size_inches(10, 10)\n","\n","fig.add_subplot(4, 3, 9)\n","plt.imshow(label_test_3, cmap = colors.ListedColormap(['black', 'green', 'blue', 'red']))\n","plt.axis('off')\n","plt.gcf().set_size_inches(10, 10)\n","\n","\n","fig.add_subplot(4, 3, 10)\n","plt.imshow(image_test_4, cmap='gray')\n","plt.axis('off')\n","plt.gcf().set_size_inches(10, 10)\n","\n","fig.add_subplot(4, 3, 11)\n","plt.imshow(pred_test_4, cmap = colors.ListedColormap(['black', 'green', 'blue', 'red']))\n","plt.axis('off')\n","plt.gcf().set_size_inches(10, 10)\n","\n","fig.add_subplot(4, 3, 12)\n","plt.imshow(label_test_4, cmap = colors.ListedColormap(['black', 'green', 'blue', 'red']))\n","plt.axis('off')\n","plt.gcf().set_size_inches(10, 10)\n","\n","\n","### End of your code ###"]}],"metadata":{"accelerator":"GPU","celltoolbar":"Slideshow","colab":{"machine_shape":"hm","provenance":[{"file_id":"1a7LkcEhJQibm4wZQIZYfSRLZE8RxlPvF","timestamp":1690516650973}],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}