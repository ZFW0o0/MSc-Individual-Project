{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":834,"status":"ok","timestamp":1690577465047,"user":{"displayName":"Zifeng Wang (George)","userId":"11537422646774520818"},"user_tz":-60},"id":"wRoIWu8ERKPc","outputId":"148d9dfe-c53d-4f21-acc3-e7ccd3fa3378"},"outputs":[{"name":"stdout","output_type":"stream","text":["Python 3.10.6\n"]}],"source":["!python --version"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":368},"executionInfo":{"elapsed":2752,"status":"error","timestamp":1693971113916,"user":{"displayName":"Zifeng Wang (George)","userId":"11537422646774520818"},"user_tz":-60},"id":"FrvaxBZsBYbu","outputId":"9175f108-223b-4b6d-d50e-c35db0e17699"},"outputs":[{"output_type":"error","ename":"MessageError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-3737b1dc60a0>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}],"source":["from google.colab import drive\n","\n","drive.mount(\"/content/gdrive\")"]},{"cell_type":"markdown","metadata":{"id":"6XRxHiKdGHiT"},"source":["# 3D-UNet reconstruction model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Eq1KWmR3HWYV"},"outputs":[],"source":["# Import libraries\n","import tarfile\n","import imageio\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset\n","import numpy as np\n","import time\n","import os\n","import random\n","import matplotlib.pyplot as plt\n","from matplotlib import colors\n","import imageio.v2 as imageio\n","\n","import nibabel as nib\n","from tqdm import tqdm\n","import glob\n","import shutil\n","import keras\n","import datetime"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mt93oQ8xZkE9"},"outputs":[],"source":["# # Download the dataset\n","# !wget https://www.dropbox.com/s/zmytk2yu284af6t/Task01_BrainTumour_2D.tar.gz\n","\n","# # Unzip the '.tar.gz' file to the current directory\n","# datafile = tarfile.open('Task01_BrainTumour_2D.tar.gz')\n","# datafile.extractall()\n","# datafile.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Zqwh9Xh_6_Q"},"outputs":[],"source":["nii_file = '/Users/zifengwang/Desktop/Imperial_Computing/Indiv_Research/Code/Zhuang_dataset/labelled_meshes/ct_train_1010_label.nii.gz'\n","nii_image = nib.load(nii_file)\n","x, y, z = nii_image.shape\n","\n","# Extract the image data as a NumPy array\n","data = nii_image.get_fdata()\n","\n","# plt.imshow(img.get_fdata()[:, :, z//2], cmap='gray')\n","\n","lv_value = 500\n","rv_value = 600\n","la_value = 420\n","\n","lv_mask = (data == lv_value)\n","lv_center_of_mass = np.mean(np.nonzero(lv_mask), axis=1)\n","\n","rv_mask = (data == rv_value)\n","rv_center_of_mass = np.mean(np.nonzero(rv_mask), axis=1)\n","\n","la_mask = (data == la_value)\n","la_center_of_mass = np.mean(np.nonzero(la_mask), axis=1)\n","\n","\n","# Extract the 2-chamber and 4-chamber views\n","# Set  all non-2chamber and non-4-chamber views pixels as 0(background value)\n","data[0:int(lv_center_of_mass[0]), 0:int(lv_center_of_mass[1]), :] = 0\n","data[(int(lv_center_of_mass[0]) + 1) : x, 0: int(lv_center_of_mass[1]), :] = 0\n","data[0:int(lv_center_of_mass[0]), (int(lv_center_of_mass[1]) + 1) : y, :] = 0\n","data[(int(lv_center_of_mass[0]) + 1) : x, (int(lv_center_of_mass[1]) + 1) : y, : ] = 0\n","\n","\n","# Save the sliced long axis views as a NIfTI file\n","sliced_img = nib.Nifti1Image(data, img.affine)\n","output_file = 'demo/ct_train_1010_4ch.nii.gz'\n","nib.save(sliced_img, output_file)\n","\n","# vector1 = rv_center_of_mass - lv_center_of_mass\n","# vector2 = lv_center_of_mass - la_center_of_mass\n","# normal_vector = np.cross(vector1, vector2)\n","\n","# normalized_normal_vector = normal_vector / np.linalg.norm(normal_vector)\n","# D = -np.dot(normalized_normal_vector, lv_center_of_mass)\n","\n","# x_range = np.arange(0, 256, 1)\n","# y_range = np.arange(0, 256, 1)\n","# z_range = np.arange(0, 256, 1)\n","# X, Y, Z = np.meshgrid(x_range, y_range, z_range)\n","\n","# Z_plane = (-normalized_normal_vector[0] * X - normalized_normal_vector[1] * Y - D) / normalized_normal_vector[2]\n","\n","# # Create a new NIfTI image using Z_plane as data\n","# new_nii = nib.Nifti1Image(Z_plane, affine=None)\n","\n","# # Set the header information (optional)\n","# new_nii.header['pixdim'] = nii_image.header['pixdim']\n","# new_nii.header['qform_code'] = nii_image.header['qform_code']\n","# new_nii.header['sform_code'] = nii_image.header['sform_code']\n","# new_nii.header['quatern_b'] = nii_image.header['quatern_b']\n","# new_nii.header['quatern_c'] = nii_image.header['quatern_c']\n","# new_nii.header['quatern_d'] = nii_image.header['quatern_d']\n","# new_nii.header['qoffset_x'] = nii_image.header['qoffset_x']\n","# new_nii.header['qoffset_y'] = nii_image.header['qoffset_y']\n","# new_nii.header['qoffset_z'] = nii_image.header['qoffset_z']\n","# new_nii.header['srow_x'] = nii_image.header['srow_x']\n","# new_nii.header['srow_y'] = nii_image.header['srow_y']\n","# new_nii.header['srow_z'] = nii_image.header['srow_z']\n","\n","# # Save the NIfTI image to a new file\n","# output_file = 'demo/ct_train_1010_4ch.nii.gz'\n","# nib.save(new_nii, output_file)\n","\n","# Z_plane = Z_plane.squeeze()\n","# plt.imshow(Z_plane, cmap='gray', origin='lower')\n","# plt.xlabel('X')\n","# plt.ylabel('Y')\n","# plt.title('Slice Plane')\n","# plt.colorbar()\n","# plt.show()\n","\n","# lowest_z_index = np.argmin(np.nonzero(lv_mask), axis=None)\n","# lv_apex = np.unravel_index(lowest_z_index, lv_mask.shape)\n","# # print(\"Center of mass:\", center_of_mass)\n","# print(\"Apex:\", lv_apex)\n","# lv_mask.shape\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e2nQL3Wz_6_R"},"outputs":[],"source":["input_dir = 'Zhuang_dataset/labelled_meshes'\n","output_dir = 'sliced_long_axis_views'\n","\n","os.makedirs(output_dir, exist_ok=True)\n","\n","nii_files = glob.glob(os.path.join(input_dir, \"*.nii.gz\"))\n","\n","for nii_file in nii_files:\n","    # Load the NIfTI file\n","    img = nib.load(nii_file)\n","    x, y, z = img.shape\n","    affine = img.affine\n","\n","    data = img.get_fdata()\n","\n","    # Extract the 2-chamber and 4-chamber views\n","    four_chamber_view = data[ :, y//2, :]\n","    two_chamber_view = data[x//2, :, :]\n","\n","    # Update the affine matrix\n","    new_affine = np.copy(affine)\n","    new_affine[0, 0] //= img.header.get_zooms()[0]\n","    new_affine[1, 1] //= img.header.get_zooms()[1]\n","    new_affine[2, 2] //= img.header.get_zooms()[2]\n","\n","    # Create the output filenames\n","    file_name = os.path.basename(nii_file)\n","    two_chamber_filename = os.path.join(output_dir, \"2ch_\" + file_name)\n","    four_chamber_filename = os.path.join(output_dir, \"4ch_\" + file_name)\n","\n","    # Save the 2-chamber view as a NIfTI file\n","    two_chamber_img = nib.Nifti1Image(two_chamber_view, new_affine)\n","    nib.save(two_chamber_img, two_chamber_filename)\n","\n","    # Save the 4-chamber view as a NIfTI file\n","    four_chamber_img = nib.Nifti1Image(four_chamber_view, new_affine)\n","    nib.save(four_chamber_img, four_chamber_filename)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"tEe1kBTeJFLI"},"source":["# Extract long axis views"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f3xv-cTm_6_S"},"outputs":[],"source":["input_dir_zhuang = 'Zhuang_dataset/labelled_meshes'\n","input_dir_bai = 'Bai_dataset/pilot_project/data/14*'\n","output_dir = '3D_long_axis_views_bai'\n","\n","os.makedirs(output_dir, exist_ok=True)\n","\n","nii_files = glob.glob(os.path.join(input_dir_bai, \"segmentation_*.nii.gz\"))\n","\n","for nii_file in nii_files:\n","    # Load the NIfTI file\n","    img = nib.load(nii_file)\n","    x, y, z, c = img.shape\n","\n","    data = img.get_fdata()\n","\n","    lv_value = 1\n","    rv_value = 4\n","\n","    lv_mask = (data == lv_value)\n","    lv_centre = np.mean(np.nonzero(lv_mask), axis=1)\n","\n","    # Extract the 2-chamber and 4-chamber views\n","    # Set all non-2chamber and non-4-chamber views pixels as 0(background value)\n","    data[0:int(lv_centre[0]), 0:int(lv_centre[1]), :] = 0\n","    data[(int(lv_centre[0]) + 1) : x, 0: int(lv_centre[1]), :] = 0\n","    data[0:int(lv_centre[0]), (int(lv_centre[1]) + 1) : y, :] = 0\n","    data[(int(lv_centre[0]) + 1) : x, (int(lv_centre[1]) + 1) : y, : ] = 0\n","\n","    #remove all cardiac structures other than left ventricle and left ventricle myocardium\n","    lv = [1,2]\n","    data = np.where(np.isin(data, lv), data, 0)\n","\n","    # Create the output filenames\n","    sample_name = os.path.basename(os.path.dirname(nii_file))\n","    sample_phase = os.path.basename(nii_file)\n","    sliced_filename = os.path.join(output_dir, sample_name + \"_\" + sample_phase)\n","\n","    # Save the sliced long axis views as a NIfTI file\n","    sliced_img = nib.Nifti1Image(data, img.affine)\n","    nib.save(sliced_img, sliced_filename)\n"]},{"cell_type":"markdown","metadata":{"id":"aFcys-pu_6_T"},"source":["# Move the nii.gz files from separate directories into the same directory"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gpBtuc7R_6_U"},"outputs":[],"source":["# import shutil\n","# #directory of 3D segmentation label files\n","# directory_path = 'Bai_dataset/pilot_project/data/14*'\n","# output_directory = '3D_label_views_bai'\n","\n","# if not os.path.exists(output_directory):\n","#     os.makedirs(output_directory)\n","\n","# # Iterate over the files in the directory\n","# for root, dirs, files in os.walk(directory_path):\n","#     for file_name in files:\n","#         if file_name.endswith('.nii.gz') and file_name.startswith('segmentation'):\n","#             img = nib.load(os.path.join(directory_path, file_name))\n","\n","#             data = img.get_fdata()\n","#             lv = [1,2]\n","#             data = np.where(np.isin(data, lv), data, 0)\n","\n","#             file_path = os.path.join(root, file_name)\n","#             new_file_name = os.path.basename(root) + '_' + file_name\n","#             new_file_path = os.path.join(output_directory, new_file_name)\n","#             # shutil.copyfile(file_path, new_file_path)\n","\n","#             # Save the views as a NIfTI file\n","#             processed_img = nib.Nifti1Image(data, img.affine)\n","#             nib.save(processed_img, new_file_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b4gnf2i2_6_V"},"outputs":[],"source":["input_dir_bai = 'Bai_dataset/pilot_project/data/14*'\n","output_dir = '3D_label_views_bai'\n","\n","os.makedirs(output_dir, exist_ok=True)\n","\n","nii_files = glob.glob(os.path.join(input_dir_bai, \"segmentation_*.nii.gz\"))\n","\n","for nii_file in nii_files:\n","    # Load the NIfTI file\n","    img = nib.load(nii_file)\n","    x, y, z, c = img.shape\n","\n","    data = img.get_fdata()\n","\n","    #remove all cardiac structures other than left ventricle and left ventricle myocardium\n","    lv = [1,2]\n","    data = np.where(np.isin(data, lv), data, 0)\n","\n","    # Create the output filenames\n","    sample_name = os.path.basename(os.path.dirname(nii_file))\n","    sample_phase = os.path.basename(nii_file)\n","    sliced_filename = os.path.join(output_dir, sample_name + \"_\" + sample_phase)\n","\n","    # Save the sliced long axis views as a NIfTI file\n","    sliced_img = nib.Nifti1Image(data, img.affine)\n","    nib.save(sliced_img, sliced_filename)\n"]},{"cell_type":"markdown","metadata":{"id":"jUfqu6og_6_W"},"source":["# Apply padding to original samples to unify sample shapes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LGIKwZ2I_6_X"},"outputs":[],"source":["import math\n","\n","input_dir_bai = '3D_label_views_bai'\n","output_dir = 'pad_3D_label_views_bai'\n","\n","os.makedirs(output_dir, exist_ok=True)\n","\n","nii_files = glob.glob(os.path.join(input_dir_bai, \"*.nii.gz\"))\n","\n","max_x = max_y = max_z = 0\n","\n","#identify the largest shape in the training samples\n","for nii_file in nii_files:\n","    # Load the NIfTI file\n","    img = nib.load(nii_file)\n","    data = img.get_fdata()\n","    print(data.shape)\n","\n","    x1, y1, z1, c1 = img.shape\n","    if x1 > max_x:\n","        max_x = x1\n","    if y1 > max_y:\n","        max_y = y1\n","    if z1 > max_z:\n","        max_z = z1\n","\n","for nii_file in nii_files:\n","    img = nib.load(nii_file)\n","    x, y, z, c = img.shape\n","    data = img.get_fdata()\n","\n","    pad_x = int((max_x - x)/2)\n","    pad_y = int((max_y - y)/2)\n","    pad_z_left = (max_z - z)//2\n","    pad_z_right = math.ceil((max_z - z) / 2)\n","\n","    padded_data = np.pad(data, pad_width=((pad_x,pad_x), (pad_y, pad_y), (pad_z_left, pad_z_right), (0,0)))\n","\n","    # print(padded_data.shape)\n","\n","    # Create the output filenames\n","    sample_name = os.path.basename(nii_file)\n","    padded_filename = os.path.join(output_dir, \"pad_\" + sample_name)\n","\n","    # Save the sliced long axis views as a NIfTI file\n","    padded_img = nib.Nifti1Image(padded_data, img.affine)\n","    nib.save(padded_img, padded_filename)"]},{"cell_type":"markdown","metadata":{"id":"axgF2run_6_Y"},"source":["# Apply padding to long-axis views"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"618l18o0_6_Z"},"outputs":[],"source":["import math\n","\n","input_dir_bai = '3D_long_axis_views_bai'\n","output_dir = 'pad_3D_long_axis_views_bai'\n","\n","os.makedirs(output_dir, exist_ok=True)\n","\n","nii_files = glob.glob(os.path.join(input_dir_bai, \"*.nii.gz\"))\n","\n","max_x = max_y = max_z = 0\n","\n","#identify the largest shape in the training samples\n","for nii_file in nii_files:\n","    # Load the NIfTI file\n","    img = nib.load(nii_file)\n","    x1, y1, z1, c1 = img.shape\n","    if x1 > max_x:\n","        max_x = x1\n","    if y1 > max_y:\n","        max_y = y1\n","    if z1 > max_z:\n","        max_z = z1\n","\n","#apply padding to the images and save the padded images to output_dir\n","for nii_file in nii_files:\n","    img = nib.load(nii_file)\n","    x, y, z, c = img.shape\n","    data = img.get_fdata()\n","\n","    pad_x = int((max_x - x)/2)\n","    pad_y = int((max_y - y)/2)\n","    pad_z_left = (max_z - z)//2\n","    pad_z_right = math.ceil((max_z - z) / 2)\n","\n","    padded_data = np.pad(data, pad_width=((pad_x,pad_x), (pad_y, pad_y), (pad_z_left, pad_z_right), (0,0)))\n","\n","    # Create the output filenames\n","    sample_name = os.path.basename(nii_file)\n","    padded_filename = os.path.join(output_dir, \"pad_\" + sample_name)\n","\n","    # Save the sliced long axis views as a NIfTI file\n","    padded_img = nib.Nifti1Image(padded_data, img.affine)\n","    nib.save(padded_img, padded_filename)"]},{"cell_type":"markdown","metadata":{"id":"PuUV2rHn_6_Z"},"source":["# Apply cropping to original images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eWCPQoJa_6_a"},"outputs":[],"source":["#function that takes a numpy array and output a cropped array\n","def crop_center_of_mass(array, centre_label = 1):\n","    # Find the center of mass of the structure with label 1\n","    indices = np.argwhere(array == centre_label)\n","    center_of_mass = np.mean(indices, axis=0)\n","\n","    # Calculate the crop boundaries\n","    x_start = int(center_of_mass[0] - 64)\n","    x_end = x_start + 128\n","    y_start = int(center_of_mass[1] - 64)\n","    y_end = y_start + 128\n","\n","    # Crop the array around the center of mass\n","    cropped_array = array[x_start:x_end, y_start:y_end, :, :]\n","\n","    return cropped_array\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yFUZuUw7_6_a"},"outputs":[],"source":["import math\n","input_dir_bai = '3D_long_axis_views_bai'\n","output_dir = 'crop_3D_long_axis_views_bai'\n","\n","os.makedirs(output_dir, exist_ok=True)\n","\n","nii_files = glob.glob(os.path.join(input_dir_bai, \"*.nii.gz\"))\n","\n","#apply cropping to the images and save the cropped images to output_dir\n","for nii_file in nii_files:\n","    img = nib.load(nii_file)\n","    x, y, z, c = img.shape\n","    data = img.get_fdata()\n","\n","    data = crop_center_of_mass(data, centre_label = 1)\n","\n","    pad_z_left = (64 - z)//2\n","    pad_z_right = math.ceil((64 - z) / 2)\n","    data = np.pad(data, pad_width=((0,0), (0,0), (pad_z_left, pad_z_right), (0,0)))\n","\n","    # Create the output filenames\n","    sample_name = os.path.basename(nii_file)\n","    cropped_filename = os.path.join(output_dir, \"crop_\" + sample_name)\n","\n","    # Save the sliced long axis views as a NIfTI file\n","    cropped_img = nib.Nifti1Image(data, img.affine)\n","    nib.save(cropped_img, cropped_filename)\n","\n","\n","input_dir_bai = '3D_label_views_bai'\n","output_dir = 'crop_3D_label_views_bai'\n","\n","os.makedirs(output_dir, exist_ok=True)\n","\n","nii_files = glob.glob(os.path.join(input_dir_bai, \"*.nii.gz\"))\n","\n","#apply cropping to the images and save the cropped images to output_dir\n","for nii_file in nii_files:\n","    img = nib.load(nii_file)\n","    x, y, z, c = img.shape\n","    data = img.get_fdata()\n","\n","    data = crop_center_of_mass(data, centre_label = 1)\n","\n","    pad_z_left = (64 - z)//2\n","    pad_z_right = math.ceil((64 - z) / 2)\n","    data = np.pad(data, pad_width=((0,0), (0,0), (pad_z_left, pad_z_right), (0,0)))\n","\n","    # Create the output filenames\n","    sample_name = os.path.basename(nii_file)\n","    cropped_filename = os.path.join(output_dir, \"crop_\" + sample_name)\n","\n","    # Save the sliced long axis views as a NIfTI file\n","    cropped_img = nib.Nifti1Image(data, img.affine)\n","    nib.save(cropped_img, cropped_filename)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eE6lrbsp_6_b","outputId":"934ef397-eff0-4b0e-8e13-78073bd3e49f"},"outputs":[{"name":"stdout","output_type":"stream","text":["(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n","(128, 128, 60, 1)\n"]}],"source":["output_dir = 'crop_3D_label_views_bai'\n","nii_files = glob.glob(os.path.join(output_dir, \"*.nii.gz\"))\n","for nii_file in nii_files:\n","    img = nib.load(nii_file)\n","    data = img.get_fdata()\n","    print(data.shape)"]},{"cell_type":"markdown","metadata":{"id":"VVNys25v_6_b"},"source":["# Separate data into training set and test set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"35zNup_L_6_c"},"outputs":[],"source":["import os\n","import random\n","import shutil\n","\n","# Set the paths to the original image and label folders\n","image_folder = 'crop_3D_long_axis_views_bai'\n","label_folder = 'crop_3D_label_views_bai'\n","\n","# Set the paths to the train and test folders\n","train_image_folder = 'crop_preprocessed_bai/train_2D'\n","train_label_folder = 'crop_preprocessed_bai/train_3D'\n","test_image_folder = 'crop_preprocessed_bai/test_2D'\n","test_label_folder = 'crop_preprocessed_bai/test_3D'\n","\n","# Create the train and test folders if they don't exist\n","os.makedirs(train_image_folder, exist_ok=True)\n","os.makedirs(train_label_folder, exist_ok=True)\n","os.makedirs(test_image_folder, exist_ok=True)\n","os.makedirs(test_label_folder, exist_ok=True)\n","\n","# Get the list of image files in the image folder\n","image_files = [file for file in os.listdir(image_folder) if file.endswith('.nii.gz')]\n","\n","# Shuffle the image files randomly\n","random.shuffle(image_files)\n","\n","# Calculate the number of files for training and testing\n","train_ratio = 0.8\n","num_train = int(len(image_files) * train_ratio)\n","num_test = len(image_files) - num_train\n","\n","# Split the image files into train and test sets\n","train_images = image_files[:num_train]\n","test_images = image_files[num_train:]\n","\n","# Move the images and labels to the respective train and test folders\n","for image in train_images:\n","    src_image_path = os.path.join(image_folder, image)\n","    dst_image_path = os.path.join(train_image_folder, image)\n","    shutil.move(src_image_path, dst_image_path)\n","\n","    # Move the corresponding label file\n","    label_file = os.path.basename(image)\n","    src_label_path = os.path.join(label_folder, label_file)\n","    dst_label_path = os.path.join(train_label_folder, label_file)\n","    shutil.move(src_label_path, dst_label_path)\n","\n","for image in test_images:\n","    src_image_path = os.path.join(image_folder, image)\n","    dst_image_path = os.path.join(test_image_folder, image)\n","    shutil.move(src_image_path, dst_image_path)\n","\n","    # Move the corresponding label file\n","    label_file = os.path.basename(image)\n","    src_label_path = os.path.join(label_folder, label_file)\n","    dst_label_path = os.path.join(test_label_folder, label_file)\n","    shutil.move(src_label_path, dst_label_path)\n"]},{"cell_type":"markdown","metadata":{"id":"5xWGT3KaML-D"},"source":["## 2. Implement a dataset class.\n","\n","It can read the imaging dataset and get items, pairs of images and label maps, as training batches."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6p6wFZ3na5z9"},"outputs":[],"source":["class CardiacImageSet(keras.utils.Sequence):\n","    \"\"\" Cardiac image set \"\"\"\n","    def __init__(self, image_path, label_path='', deploy=False):\n","        self.image_path = image_path\n","        self.deploy = deploy\n","        self.images = []\n","        self.labels = []\n","\n","        image_names = [file for file in os.listdir(image_path) if file.endswith('.nii.gz')]\n","        for image_name in image_names:\n","            # Read the image\n","            image = nib.load(os.path.join(image_path, image_name))\n","            image = image.get_fdata()\n","            #transpose image dimension from XYZC to CXYZ\n","            image = np.transpose(image, (3, 0, 1, 2))\n","            self.images += [image]\n","\n","            # Read the label map\n","            if not self.deploy:\n","                label_name = os.path.join(label_path, image_name)\n","                label = nib.load(label_name)\n","                label = label.get_fdata()\n","                label = np.transpose(label, (3, 0, 1, 2))\n","                self.labels += [label]\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        # Get an image and perform intensity normalisation\n","        # Dimension: XYZ\n","        # image = normalise_intensity(self.images[idx])\n","        image = self.images[idx]\n","\n","        # Get its label map\n","        # Dimension: XYZ\n","        label = self.labels[idx]\n","        return image, label\n","\n","    def get_random_batch(self, batch_size):\n","        # Get a batch of paired images and label maps\n","        # Dimension of images: NCXYZ\n","        # Dimension of labels: NXYZ\n","        images, labels = [], []\n","\n","        ### Insert your code ###\n","        for i in range(batch_size):\n","            #randomly retrieve an image and label map\n","            random_idx = random.randint(0,self.__len__() - 1)\n","            random_image, random_label = self.__getitem__(random_idx)\n","            images += [random_image]\n","            labels += [random_label]\n","\n","        #Turn the list into np array\n","        images = np.array(images)\n","        labels = np.array(labels)\n","        ### End of your code ###\n","        return images, labels\n","\n","    def get_batch(self, batch_size, iteration_num):\n","      images, labels = [], []\n","      batch_num = self.__len__()//batch_size\n","      image_idx = ((iteration_num % batch_num) - 1) * batch_size\n","      for i in range(batch_size):\n","        image, label = self.__getitem__(image_idx + i)\n","        images += [image]\n","        labels += [label]\n","\n","      images = np.array(images)\n","      labels = np.array(labels)\n","      return images, labels\n","\n","# train_set = CardiacImageSet('/content/gdrive/My Drive/crop_preprocessed_bai/train_2D', '/content/gdrive/My Drive/crop_preprocessed_bai/train_3D')\n","# test_set = CardiacImageSet('/content/gdrive/My Drive/crop_preprocessed_bai/test_2D', '/content/gdrive/My Drive/crop_preprocessed_bai/test_3D')\n","\n","# image_1, label_1 = train_set.__getitem__(88)\n","# print(image_1.shape)\n","# print(label_1.shape)\n","\n","# test_images, test_labels = train_set.get_random_batch(4)\n","# print(test_images.shape)\n","# print(test_labels.shape)\n","# print(test_images.dtype)\n"]},{"cell_type":"markdown","metadata":{"id":"pa4ZpawDNmwu"},"source":["## Construct a U-net architecture.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":301,"status":"ok","timestamp":1693403130156,"user":{"displayName":"Zifeng Wang (George)","userId":"11537422646774520818"},"user_tz":-60},"id":"IMPmBZVGb1aI","outputId":"ad8973fa-ef54-4a1a-ed2e-d4dd7c27ddc9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of parameters in the model: 6407491\n"]}],"source":["class UNet3d(nn.Module):\n","    def contracting_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n","        block = torch.nn.Sequential(\n","            torch.nn.Conv3d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=1),\n","            torch.nn.LeakyReLU(0.1),\n","            torch.nn.BatchNorm3d(mid_channel),\n","            torch.nn.Conv3d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=out_channels, padding=1),\n","            torch.nn.LeakyReLU(0.1),\n","            torch.nn.BatchNorm3d(out_channels),\n","        )\n","        return block\n","\n","    def expansive_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n","        block = torch.nn.Sequential(\n","            torch.nn.Conv3d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=1),\n","            torch.nn.LeakyReLU(0.1),\n","            torch.nn.BatchNorm3d(mid_channel),\n","            torch.nn.Conv3d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel, padding=1),\n","            torch.nn.LeakyReLU(0.1),\n","            torch.nn.BatchNorm3d(mid_channel),\n","            torch.nn.ConvTranspose3d(in_channels=mid_channel, out_channels=out_channels, kernel_size=3, stride=2,\n","                                     padding=1, output_padding=1)\n","        )\n","        return block\n","\n","    def final_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n","        block = torch.nn.Sequential(\n","            torch.nn.Conv3d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=1),\n","            torch.nn.LeakyReLU(0.1),\n","            torch.nn.BatchNorm3d(mid_channel),\n","            torch.nn.Conv3d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel, padding=1),\n","            torch.nn.LeakyReLU(0.1),\n","            torch.nn.BatchNorm3d(mid_channel),\n","            torch.nn.Conv3d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=out_channels, padding=1),\n","            torch.nn.Sigmoid()\n","        )\n","        return block\n","\n","    def __init__(self, in_channel, out_channel):\n","        super(UNet3d, self).__init__()\n","        # Encode\n","        self.conv_encode1 = self.contracting_block(in_channel, 16, 32)\n","        self.conv_maxpool1 = torch.nn.MaxPool3d(kernel_size=2)\n","        self.conv_encode2 = self.contracting_block(32, 32, 64)\n","        self.conv_maxpool2 = torch.nn.MaxPool3d(kernel_size=2)\n","        self.conv_encode3 = self.contracting_block(64, 64, 128)\n","        self.conv_maxpool3 = torch.nn.MaxPool3d(kernel_size=2)\n","        # Bottleneck\n","        self.bottleneck = torch.nn.Sequential(\n","            torch.nn.Conv3d(kernel_size=3, in_channels=128, out_channels=128, padding=1),\n","            torch.nn.LeakyReLU(0.1),\n","            torch.nn.BatchNorm3d(128),\n","            torch.nn.Conv3d(kernel_size=3, in_channels=128, out_channels=256, padding=1),\n","            torch.nn.LeakyReLU(0.1),\n","            torch.nn.BatchNorm3d(256),\n","            torch.nn.ConvTranspose3d(in_channels=256, out_channels=256, kernel_size=3, stride=2, padding=1,\n","                                     output_padding=1)\n","        )\n","        # Decode\n","        self.conv_decode3 = self.expansive_block(128+256, 128, 128)\n","        self.conv_decode2 = self.expansive_block(64+128, 64, 64)\n","        self.final_layer = self.final_block(32+64, 32, out_channel)\n","\n","    def crop_and_concat(self, upsampled, bypass, crop=False):\n","        if crop:\n","            c = (bypass.size()[2] - upsampled.size()[2]) // 2\n","            bypass = F.pad(bypass, (-c, -c, -c, -c))\n","        # print(\"unsampled shape:\", upsampled.shape)\n","        # print(\"bypass shape:\", bypass.shape)\n","\n","        return torch.cat((upsampled, bypass), 1)\n","\n","    def forward(self, x):\n","        # Encode\n","        encode_block1 = self.conv_encode1(x)\n","        encode_pool1 = self.conv_maxpool1(encode_block1)\n","        encode_block2 = self.conv_encode2(encode_pool1)\n","        encode_pool2 = self.conv_maxpool2(encode_block2)\n","        encode_block3 = self.conv_encode3(encode_pool2)\n","        encode_pool3 = self.conv_maxpool3(encode_block3)\n","        # Bottleneck\n","        bottleneck1 = self.bottleneck(encode_pool3)\n","        # Decode\n","        decode_block3 = self.crop_and_concat(bottleneck1, encode_block3, crop=False)\n","        cat_layer2 = self.conv_decode3(decode_block3)\n","        decode_block2 = self.crop_and_concat(cat_layer2, encode_block2, crop=False)\n","        cat_layer1 = self.conv_decode2(decode_block2)\n","        decode_block1 = self.crop_and_concat(cat_layer1, encode_block1, crop=False)\n","        final_layer = self.final_layer(decode_block1)\n","        return final_layer\n","\n","    def count_parameters(self):\n","        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n","\n","\n","toy_model = UNet3d(in_channel=1, out_channel=3)\n","total_parameters = toy_model.count_parameters()\n","print(\"Total number of parameters in the model:\", total_parameters)"]},{"cell_type":"markdown","metadata":{"id":"NcNWZS08d47P"},"source":["## 4. Train the segmentation model."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":484787,"status":"ok","timestamp":1690404330560,"user":{"displayName":"Zifeng Wang (George)","userId":"11537422646774520818"},"user_tz":-60},"id":"xaGGkKQndIaR","outputId":"1dde7da5-fb1b-4348-ff37-b700f1bac5bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Device: cuda\n","training loss for epoch 1.0:\n","0.6309710741043091\n","test loss for iteration 1.0:\n","0.5744005441665649\n","training loss for epoch 2.0:\n","0.5774275064468384\n","test loss for iteration 2.0:\n","0.5718958377838135\n","training loss for epoch 3.0:\n","0.573948085308075\n","test loss for iteration 3.0:\n","0.5708145499229431\n","training loss for epoch 4.0:\n","0.5708648562431335\n","test loss for iteration 4.0:\n","0.8764143586158752\n","training loss for epoch 5.0:\n","0.5693016052246094\n","test loss for iteration 5.0:\n","0.5715335607528687\n","training loss for epoch 6.0:\n","0.5685228109359741\n","test loss for iteration 6.0:\n","1.1640300750732422\n","Training took 1464.462s in total.\n"]}],"source":["# CUDA device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Device: {0}'.format(device))\n","\n","# Build the model\n","num_class = 3\n","model = UNet3d(in_channel=1, out_channel=num_class)\n","model = model.to(device)\n","params = list(model.parameters())\n","\n","model_dir = '/content/gdrive/My Drive/saved_model'\n","if not os.path.exists(model_dir):\n","    os.makedirs(model_dir)\n","\n","# Optimizer\n","optimizer = optim.Adam(params, lr=1e-3)\n","\n","# Segmentation loss\n","criterion = nn.CrossEntropyLoss()\n","\n","train_image_folder = '/content/gdrive/My Drive/crop_preprocessed_bai/train_2D'\n","train_label_folder = '/content/gdrive/My Drive/crop_preprocessed_bai/train_3D'\n","test_image_folder = '/content/gdrive/My Drive/crop_preprocessed_bai/test_2D'\n","test_label_folder = '/content/gdrive/My Drive/crop_preprocessed_bai/test_3D'\n","\n","# Datasets\n","train_set = CardiacImageSet(train_image_folder, train_label_folder)\n","test_set = CardiacImageSet(test_image_folder, test_label_folder)\n","\n","# Train the model\n","\n","num_iter = 500\n","train_batch_size = 4\n","eval_batch_size = 4\n","start = time.time()\n","running_loss = 0\n","#number of batches in an epoch\n","num_batches = train_set.__len__()/train_batch_size\n","for it in range(1, 1 + num_iter):\n","    # Set the modules in training mode, which will have effects on certain modules, e.g. dropout or batchnorm.\n","    start_iter = time.time()\n","    model.train()\n","\n","    # Get a batch of images and labels\n","    images, labels = train_set.get_batch(train_batch_size, it)\n","    images, labels = torch.from_numpy(images), torch.from_numpy(labels)\n","    # image.to() convert the array from system RAM to GPU RAM\n","    images, labels = images.to(device, dtype=torch.float32), labels.to(device, dtype=torch.long)\n","    #remove the channel dimension in the labels array\n","    labels = labels.squeeze(axis = 1)\n","    # print(\"Images shape:\", images.shape)\n","    logits = model(images)\n","\n","    # Perform optimisation and print out the training loss\n","    # print('logits shape:', logits.shape)\n","    # print('label shape:', labels.shape)\n","\n","    loss = criterion(logits, labels)\n","    running_loss += loss\n","\n","    if it % num_batches == 0:\n","        epoch_loss = running_loss/num_batches\n","        running_loss = 0\n","        print (\"training loss for epoch {}:\".format(it/num_batches))\n","        print(epoch_loss.item())\n","\n","    loss.backward()\n","    optimizer.step()\n","    optimizer.zero_grad()\n","\n","    ###   ###\n","\n","    # Evaluate\n","    if it % num_batches == 0:\n","        model.eval()\n","        # Disabling gradient calculation during reference to reduce memory consumption\n","        with torch.no_grad():\n","            # Evaluate on a batch of test images and print out the test loss\n","            ### Insert your code ###\n","            test_images, test_labels = test_set.get_random_batch(eval_batch_size)\n","            test_images, test_labels = torch.from_numpy(test_images), torch.from_numpy(test_labels)\n","            test_images, test_labels = test_images.to(device, dtype=torch.float32), test_labels.to(device, dtype=torch.long)\n","            test_labels = test_labels.squeeze(axis = 1)\n","            test_logits = model(test_images)\n","            test_loss = criterion(test_logits, test_labels)\n","            print (\"test loss for iteration {}:\".format(it/num_batches))\n","            print(test_loss.item())\n","            ### End of your code ###\n","\n","    # Save the model\n","    if it % num_batches == 0:\n","        epoch = it/num_batches\n","        torch.save(model.state_dict(), os.path.join(model_dir, 'model_{0}.pt'.format(epoch)))\n","print('Training took {:.3f}s in total.'.format(time.time() - start))"]},{"cell_type":"markdown","metadata":{"id":"_9l7P_WeFmcT"},"source":["# prediction generation\n","\n","---\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rOAr9DR4FlNg"},"outputs":[],"source":["import datetime\n","\n","device = torch.device(\"cpu\")\n","def model_load():\n","\n","    unet = UNet3d(in_channel=1, out_channel=3)\n","    unet.to(device, dtype=torch.float)\n","\n","    model_list = ['/content/gdrive/My Drive/saved_model/aug_10/model_20.0.pt']\n","    model_i = model_list[0]\n","    checkpoint = torch.load(model_i, map_location=torch.device('cpu'))\n","    unet.load_state_dict(checkpoint)\n","    return unet\n","\n","def mr_lax_inference(unet, slice_img):\n","\n","    img = nib.load(slice_img)\n","    affine = img.affine\n","    data = img.get_fdata()\n","    data = np.transpose(data, (3, 0, 1, 2))\n","\n","    # print(\"sliced image shape:\", data.shape)\n","\n","    data = np.expand_dims(data, axis=(0))\n","\n","    # print(data.shape)\n","\n","    data = torch.from_numpy(data)\n","\n","    # print(data.size())\n","    data = data.to(device, dtype=torch.float32)\n","\n","    # print(data.size())\n","\n","    unet.eval()\n","    output = unet(data)\n","    pred = output.detach().cpu().numpy()\n","    pred = np.argmax(pred, 1)\n","    # print(pred.shape)\n","    pred_nifti = nib.Nifti1Image(pred.squeeze(), affine=affine)\n","\n","    #pred_nifti is a Nifti object, pred is a numpy array\n","    return pred_nifti, pred\n","\n","# sliced_image = '/content/gdrive/My Drive/crop_preprocessed_bai/test_2D/crop_14AB01345_segmentation_ES.nii.gz'\n","unet = model_load()\n","# pred_nifti, pred = mr_lax_inference(unet, sliced_image)\n","\n","\n","# pred_save_dir = '/content/gdrive/My Drive/pred_output/pred_4.nii.gz'\n","# nib.save(pred_nifti, pred_save_dir)\n","\n","\n","# ground_truth_file = '/content/gdrive/My Drive/crop_preprocessed_bai/test_3D/crop_14AB01345_segmentation_ES.nii.gz'\n","# ground_truth = nib.load(ground_truth_file)\n","\n","# # Extract the image data as a NumPy array\n","# ground_truth = ground_truth.get_fdata()\n","# num_labels = 3\n","# pred = np.transpose(pred, (1, 2, 3, 0))\n","# total_dice_score = dice_score(ground_truth, pred, num_labels)\n","# print(\"Total Dice score:\", total_dice_score)\n","# print(\"Label dice scores:\", dice_scores)"]},{"cell_type":"markdown","metadata":{"id":"MpOV4ianD68R"},"source":["# Evaluation functions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8067,"status":"ok","timestamp":1693403173300,"user":{"displayName":"Zifeng Wang (George)","userId":"11537422646774520818"},"user_tz":-60},"id":"8R99g2kZD5b7","outputId":"a9e38cad-7b5d-4259-9d81-889802839cc2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting SimpleITK\n","  Downloading SimpleITK-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: SimpleITK\n","Successfully installed SimpleITK-2.2.1\n"]}],"source":["from functools import partial\n","\n","import numpy as np\n","!pip install SimpleITK\n","import SimpleITK as sitk\n","from SimpleITK import GetArrayViewFromImage as ArrayView\n","\n","# dice_scores = []\n","def dice_score(ground_truth, predicted, num_labels):\n","    total_intersection = 0\n","    total_gt_count = 0\n","    total_pred_count = 0\n","\n","    for label in range(1, num_labels):  # Start from label 1, assuming label 0 is background\n","        # Create binary masks for the specific label\n","        gt_mask = (ground_truth == label)\n","        pred_mask = (predicted == label)\n","\n","        intersection = np.logical_and(gt_mask, pred_mask).sum()\n","        gt_count = gt_mask.sum()\n","        pred_count = pred_mask.sum()\n","\n","        label_dice = (2.0 * intersection) / (gt_count + pred_count)\n","        # dice_scores.append(label_dice)\n","\n","        total_intersection += intersection\n","        total_gt_count += gt_count\n","        total_pred_count += pred_count\n","\n","    dice = (2.0 * total_intersection) / (total_gt_count + total_pred_count)\n","    return dice\n","\n","distance_map = partial(sitk.SignedMaurerDistanceMap, squaredDistance=False, useImageSpacing=True)\n","def hausdorf(gold, prediction, num_labels = 1):\n","    for label in range(1, num_labels + 1):\n","        gold_surface = sitk.LabelContour(gold == label, False)\n","        prediction_surface = sitk.LabelContour(prediction == label, False)\n","\n","        ### Get distance map for contours (the distance map computes the minimum distances)\n","        prediction_distance_map = sitk.Abs(distance_map(prediction_surface))\n","        gold_distance_map = sitk.Abs(distance_map(gold_surface))\n","\n","        ### Find the distances to surface points of the contour.  Calculate in both directions\n","        gold_to_prediction = ArrayView(prediction_distance_map)[ArrayView(gold_surface) == 1]\n","        prediction_to_gold = ArrayView(gold_distance_map)[ArrayView(prediction_surface) == 1]\n","\n","        ### Find the 95% Distance for each direction and average\n","\n","        hausdorf_dis = (np.percentile(prediction_to_gold, 95) + np.percentile(gold_to_prediction, 95)) / 2.0\n","        return hausdorf_dis\n","\n","def segmentation_accuracy(groundtruth, prediction):\n","    unique_categories = np.unique(groundtruth)\n","    unique_categories = unique_categories[unique_categories != 0]  # Remove background 0\n","\n","    per_category_accuracies = []\n","\n","    for category in unique_categories:\n","        category_mask = (groundtruth == category)\n","        category_pred_mask = (prediction == category)\n","\n","        intersect = np.sum(category_pred_mask * category_mask)\n","        union = np.sum(category_pred_mask) + np.sum(category_mask) - intersect\n","        xor = np.sum(category_mask == category_pred_mask)\n","\n","        category_acc = xor / (union + xor - intersect)\n","        per_category_accuracies.append(category_acc)\n","\n","    overall_intersect = np.sum(prediction * groundtruth)\n","    overall_union = np.sum(prediction) + np.sum(groundtruth) - overall_intersect\n","    overall_xor = np.sum(groundtruth == prediction)\n","\n","    overall_acc = overall_xor / (overall_union + overall_xor - overall_intersect)\n","\n","    return per_category_accuracies, overall_acc\n","\n","\n","\n","def jaccard_score(ground_truth, predicted, num_labels = 3):\n","    \"\"\"\n","    Calculate the Jaccard similarity score (IoU) for multi-label 3D object segmentation.\n","\n","    Parameters:\n","    ground_truth (numpy.ndarray): Ground truth 3D object segmentation (3D binary array).\n","    predicted (numpy.ndarray): Predicted 3D object segmentation (3D binary array).\n","\n","    Returns:\n","    float: Average Jaccard similarity score across all labels.\n","    \"\"\"\n","    # unique_labels = np.unique(np.concatenate((ground_truth, predicted)))\n","    # num_labels = len(unique_labels)\n","    jaccard_scores = np.zeros(num_labels - 1)\n","\n","    for label in range(1, num_labels):\n","        gt_mask = (ground_truth == label)\n","        pred_mask = (predicted == label)\n","\n","        intersection = np.logical_and(gt_mask, pred_mask).sum()\n","        union = np.logical_or(gt_mask, pred_mask).sum()\n","\n","        # intersection = len(list(set(gt_mask).intersection(pred_mask)))\n","        # union = (len(gt_mask) + len(pred_mask)) - intersection\n","\n","        if union == 0:\n","            jaccard_scores[label - 1] = 1.0  # Handle division by zero\n","        else:\n","            jaccard_scores[label - 1] = float(intersection) / union\n","\n","    average_jaccard_score = np.mean(jaccard_scores)\n","    return jaccard_scores, average_jaccard_score\n"]},{"cell_type":"markdown","metadata":{"id":"g8FF6f113z-l"},"source":["# visualise model output"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zi5wTNCJ3fct","outputId":"f1eae63c-651b-4f7d-f966-c64daed1b823","executionInfo":{"status":"ok","timestamp":1693403917263,"user_tz":-60,"elapsed":743975,"user":{"displayName":"Zifeng Wang (George)","userId":"11537422646774520818"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-3421ba67dd9c>:40: FutureWarning: Image data has type int64, which may cause incompatibilities with other tools. This will error in NiBabel 5.0. This warning can be silenced by passing the dtype argument to Nifti1Image().\n","  pred_nifti = nib.Nifti1Image(pred.squeeze(), affine=affine)\n"]},{"output_type":"stream","name":"stdout","text":["Dice scores: [0.9294411237899737, 0.8720792265310198, 0.9018845852623648, 0.9129241813004272, 0.9134732279718801, 0.9090068334789086, 0.9319724321298629, 0.92623274681277, 0.897038567493113, 0.9111706845118117, 0.9056220217275625, 0.8906899275387204, 0.8897964328480494, 0.8983589272196388, 0.929596870105478, 0.9041064243497681, 0.8974618396164167, 0.9301509636613163, 0.9118384228102097, 0.9018107660512161, 0.9053351400750008, 0.9152244211615573, 0.9008384345353796, 0.9156550647257341, 0.8937129896322643, 0.8950645190457123, 0.8866197006123457, 0.8804563666088958, 0.915187590971302, 0.9047629345299237, 0.9213992623696773, 0.9144273246417411, 0.9167299870379475, 0.9122152907237109, 0.864537687966962, 0.8975906818423572, 0.8998296935854294, 0.9260909508497933, 0.9169761893623989, 0.8997911855202284, 0.9008133391004928, 0.924111792979682, 0.8608301613195577, 0.9206040276139993, 0.8965547349656201, 0.8995680789798437, 0.9248455847417363, 0.908755306712607, 0.9152240238593123, 0.8811799279878352, 0.9274535862430027, 0.9136188898849771, 0.9056016270771556, 0.9082553614308189, 0.906527945032979, 0.9165332372247463, 0.9037464529029323, 0.8898931248575221, 0.9252396001622007, 0.9273627429247026, 0.9017046844119533, 0.9067674261222648, 0.9167279390310796, 0.9027287685825431, 0.9334196103806974, 0.9163749193404451, 0.9051418023683264, 0.9209524845058171, 0.9210031731601354, 0.92022169361363, 0.9343532684283727, 0.9173559263554376, 0.8973332703379477, 0.9069517833553501, 0.9159636323909639, 0.9203310615053835, 0.9080675685147543, 0.8692695825800707, 0.8859448226138219, 0.8998682812831953, 0.90459651519335, 0.9119675615066689, 0.8969161540684474, 0.9142834890965732, 0.9102058371735791, 0.9254517076267823, 0.9115354528691959, 0.8867299076223503, 0.9137180017423596, 0.9114549352222947, 0.924298723047938, 0.9141543178334185, 0.9073805986661188, 0.8938728078195879, 0.9203905238478497, 0.9109664641379809, 0.8875340914202067, 0.8807686667737363, 0.9174556913866496, 0.9068208250667031, 0.9118997855833553, 0.9175788845763513, 0.9208410525747792, 0.8917760494432435, 0.9242355348414232, 0.9212622257581916, 0.9098479915756305, 0.9163350992504011, 0.9109678590884329, 0.9131511371973587, 0.9272424708782203, 0.8905290927744394, 0.9302165333778789, 0.9114987902712339, 0.9056041354199093, 0.9116010849290967, 0.9294050488392744, 0.8938701088214864, 0.9212149284200956, 0.9026168956178419, 0.9154134509371554, 0.8919792105632813, 0.8797485970819304, 0.9225736381361144, 0.9047845820415383, 0.9138040309291419, 0.920576716160964, 0.91580219646444, 0.9081771166380597, 0.9176579712938258, 0.8834158825303843, 0.8777643970351857, 0.924000866792558, 0.8549214380207487, 0.9035407398378938, 0.9212637294829076, 0.9291997453321726, 0.9096896260214967, 0.9244664810948736, 0.9274347221506927, 0.9077043458820315, 0.9080962425614378, 0.8979429098294273, 0.8887479769065392, 0.9208451144485017, 0.9173067509234124, 0.9219775620412621, 0.9211351846200794, 0.9251567328918322, 0.9062543822745758, 0.9023661461815643, 0.9186195961610071, 0.9064936442550784, 0.8998651878873016, 0.9211391342974187, 0.907337128399747, 0.9165895336418655, 0.9040953090096798, 0.904456426056338, 0.9204749775247228]\n","Mean Dice Score: 0.9086207454474525\n","Hausdorf distances: [1.7677669525146484, 3.699821460247013, 3.165309429168701, 2.6475424766540527, 2.5, 1.9999923706054688, 1.7677669525146484, 1.999995231628418, 2.7950849533081055, 2.0000076293945312, 2.3584952354431152, 2.6475424766540527, 2.6475424766540527, 2.5, 2.218166691064847, 2.5, 2.0, 1.5088834762573242, 2.6475424766540527, 2.584634780883789, 1.8838796615600586, 2.1792476177215576, 3.1160084009170532, 1.7677669525146484, 3.1160084009170532, 2.7321743965148926, 2.5172459363937376, 3.116005539894104, 2.4292476177215576, 2.5, 1.7677669525146484, 2.4292492866516113, 2.0, 2.6475424766540527, 2.584634780883789, 2.7950849533081055, 3.1160084009170532, 1.7677669525146484, 3.1160084009170532, 2.5846376419067383, 2.25, 1.7677669525146484, 3.976431131362915, 2.0, 2.6475424766540527, 2.7950849533081055, 2.4292508363723755, 2.358496904373169, 2.6475424766540527, 2.5, 2.4292476177215576, 1.7677669525146484, 3.1160084009170532, 2.2500038146972656, 2.9684659242630005, 2.732177257537842, 2.6475424766540527, 3.1160084009170532, 2.0, 2.25, 2.4292452335357666, 2.732177257537842, 2.1792508363723755, 2.7321786880493164, 1.7677669525146484, 2.25, 2.7950849533081055, 1.7677669525146484, 1.8838872909545898, 1.7677669525146484, 1.7677669525146484, 2.179254651069641, 2.6898584365844727, 2.6475424766540527, 1.9999923706054688, 1.8838872909545898, 2.669264554977417, 3.4059553384779537, 2.9983259439468384, 2.5, 2.5, 2.179248571395874, 2.1792461216449737, 2.5, 1.8838834762573242, 1.7677669525146484, 2.5, 2.5, 1.8838872909545898, 2.25, 1.8838834762573242, 1.8838872909545898, 2.5, 3.436936140060425, 1.8838796615600586, 1.8838834762573242, 3.368548035621643, 2.7321743965148926, 2.1792476177215576, 2.669269561767578, 2.2499990463256836, 2.25, 2.25, 2.732177257537842, 1.7677669525146484, 2.063131093978882, 2.5, 1.8838825225830078, 2.133883476257324, 1.25, 1.7677669525146484, 3.9528470039367676, 1.7677669525146484, 1.7677669525146484, 2.1792476177215576, 2.4292476177215576, 1.25, 2.58463191986084, 1.7677669525146484, 2.4292476177215576, 2.5, 3.1160084009170532, 2.647540807723999, 1.5088834762573242, 2.25, 1.9999961853027344, 2.358501672744751, 2.4292443990707397, 1.8838834762573242, 2.0, 2.6475424766540527, 3.486232876777649, 1.5088834762573242, 3.165309429168701, 2.8507810831069946, 2.5, 1.8838834762573242, 2.358492851257324, 1.9999961853027344, 1.7677669525146484, 1.9012965679168807, 2.751050567626936, 2.5, 2.9983235597610474, 1.8838796615600586, 1.7677669525146484, 1.9999847412109375, 1.4820968508720398, 1.7677669525146484, 2.6692724227905273, 2.1672074794769287, 1.25, 2.46875, 2.1863228559493955, 1.7057000070810318, 2.454010951519006, 2.584634780883789, 2.6475424766540527, 2.7950849533081055, 2.1792476177215576]\n","Mean Hausdorf distance: 2.3524027986265708\n","per cat accuracies: [array([0.9183434 , 0.84452805]), array([0.8751768, 0.6473421]), array([0.90769439, 0.69201469]), array([0.90885315, 0.75255535]), array([0.8836018 , 0.81845599]), array([0.89418953, 0.79239203]), array([0.93665907, 0.77501757]), array([0.93558431, 0.76054598]), array([0.85315254, 0.7903987 ]), array([0.90004508, 0.81133742]), array([0.91828622, 0.70770908]), array([0.89152256, 0.67751745]), array([0.90498858, 0.64857416]), array([0.90871598, 0.69853124]), array([0.93414579, 0.74823012]), array([0.91282089, 0.67455678]), array([0.88604635, 0.76855346]), array([0.91814773, 0.85106579]), array([0.91519242, 0.73679149]), array([0.88719498, 0.79699261]), array([0.86988706, 0.80838843]), array([0.88948329, 0.81576623]), array([0.86617001, 0.79497571]), array([0.90620678, 0.81974514]), array([0.90115492, 0.67631372]), array([0.9026237 , 0.65861325]), array([0.8575776 , 0.77049636]), array([0.89645647, 0.65000562]), array([0.92331097, 0.71962832]), array([0.91666406, 0.67092541]), array([0.89847716, 0.83164817]), array([0.90294664, 0.78855665]), array([0.86921817, 0.83782259]), array([0.85100856, 0.8344491 ]), array([0.88333444, 0.63888147]), array([0.88828784, 0.73044998]), array([0.91344628, 0.68269655]), array([0.90355203, 0.84088617]), array([0.91767654, 0.72534519]), array([0.90350793, 0.70821868]), array([0.87194991, 0.79828252]), array([0.912722  , 0.83340213]), array([0.8754928 , 0.58800176]), array([0.88891759, 0.8352655 ]), array([0.90487509, 0.69737817]), array([0.89299141, 0.7113738 ]), array([0.89846771, 0.84129492]), array([0.92957219, 0.70509617]), array([0.88127589, 0.82052723]), array([0.88946653, 0.64064811]), array([0.9033874 , 0.84124647]), array([0.91115942, 0.79684724]), array([0.91402551, 0.69036385]), array([0.8908174 , 0.79491086]), array([0.91604531, 0.68476581]), array([0.91639359, 0.73614172]), array([0.86577629, 0.79765544]), array([0.85366826, 0.77190252]), array([0.92394954, 0.77576406]), array([0.89426594, 0.85146303]), array([0.91650714, 0.70271071]), array([0.87377411, 0.7946376 ]), array([0.88598956, 0.82738455]), array([0.89863813, 0.73546176]), array([0.91875722, 0.8516412 ]), array([0.91847791, 0.74314389]), array([0.88631745, 0.79024345]), array([0.8945405 , 0.83126917]), array([0.90250147, 0.82280753]), array([0.90265036, 0.81932431]), array([0.91027127, 0.85972173]), array([0.90436937, 0.8032334 ]), array([0.90072202, 0.6886553 ]), array([0.87174997, 0.80653767]), array([0.90625728, 0.80667928]), array([0.93407957, 0.73252107]), array([0.89889825, 0.78746837]), array([0.88423231, 0.6256613 ]), array([0.90541669, 0.60093637]), array([0.90886977, 0.68680655]), array([0.91590201, 0.68820413]), array([0.92441805, 0.69160844]), array([0.8913951 , 0.76080896]), array([0.92453662, 0.72545215]), array([0.90918885, 0.79433493]), array([0.90739147, 0.84005174]), array([0.89593883, 0.8011933 ]), array([0.91286523, 0.64785209]), array([0.90892777, 0.80850196]), array([0.92843564, 0.70859371]), array([0.93946007, 0.73797739]), array([0.90428905, 0.81322786]), array([0.91361183, 0.71819418]), array([0.89806509, 0.696875  ]), array([0.90858424, 0.82398591]), array([0.90809058, 0.79154461]), array([0.89896849, 0.64375661]), array([0.89520074, 0.62147837]), array([0.92395176, 0.73311706]), array([0.9153441 , 0.70493313]), array([0.92652154, 0.69325596]), array([0.92224218, 0.74061672]), array([0.90514233, 0.82374797]), array([0.89891981, 0.67478716]), array([0.92070736, 0.81514699]), array([0.90479367, 0.82827111]), array([0.88805703, 0.80317118]), array([0.89273943, 0.83264388]), array([0.8984253, 0.7960646]), array([0.90621891, 0.80628272]), array([0.91669435, 0.83602962]), array([0.89551186, 0.7061929 ]), array([0.912985  , 0.85176833]), array([0.91336551, 0.80767478]), array([0.87937428, 0.80967159]), array([0.90027963, 0.80861443]), array([0.92136601, 0.84519219]), array([0.90265468, 0.65768422]), array([0.93052333, 0.74707652]), array([0.89119848, 0.78873239]), array([0.92055983, 0.76108781]), array([0.90326486, 0.65263839]), array([0.89322127, 0.63524182]), array([0.90539731, 0.83679354]), array([0.89303896, 0.79140046]), array([0.9253161 , 0.71868979]), array([0.89988729, 0.83014139]), array([0.90063939, 0.81091994]), array([0.9091991, 0.7909656]), array([0.9341305 , 0.72120297]), array([0.86383699, 0.7617485 ]), array([0.89926089, 0.64021374]), array([0.9174796 , 0.83202188]), array([0.82410928, 0.71527778]), array([0.9190319 , 0.67780005]), array([0.9215782, 0.7693002]), array([0.914785  , 0.84005091]), array([0.92090884, 0.75494082]), array([0.93641308, 0.74314569]), array([0.93584275, 0.7543565 ]), array([0.90718133, 0.78431516]), array([0.88515172, 0.80650748]), array([0.91344929, 0.68501649]), array([0.89828466, 0.68767282]), array([0.90517038, 0.82721912]), array([0.91274006, 0.81864991]), array([0.90885716, 0.82686403]), array([0.91589657, 0.83119328]), array([0.92170526, 0.82342815]), array([0.91418642, 0.71300362]), array([0.92367676, 0.69285609]), array([0.92388488, 0.81491605]), array([0.91946386, 0.71470732]), array([0.89642877, 0.77194014]), array([0.90325593, 0.83322102]), array([0.89688522, 0.78124895]), array([0.92083056, 0.74482012]), array([0.88811528, 0.78997696]), array([0.91559266, 0.71013297]), array([0.89733287, 0.83371225])]\n","Mean per cat jaccard score: 0.831398828055385\n"]}],"source":["sliced_images = '/content/gdrive/My Drive/aug_10_preprocessed_bai/test_2D'\n","pred_save_dir = '/content/gdrive/My Drive/pred_output'\n","pred_load_dir = '/content/gdrive/My Drive/pred_output/08-30_13-46'\n","ground_truth_dir = '/content/gdrive/My Drive/aug_10_preprocessed_bai/test_3D'\n","predicted = False\n","\n","# Get the current time\n","current_time = datetime.datetime.now()\n","time_string = current_time.strftime(\"%m-%d_%H-%M\")\n","\n","#create a new directory and name it with current time\n","if not predicted:\n","    pred_save_dir = os.path.join(pred_save_dir, time_string)\n","    os.makedirs(pred_save_dir, exist_ok=True)\n","\n","sliced_nii_files = glob.glob(os.path.join(sliced_images, \"*.nii.gz\"))\n","\n","\n","dice_scores = []\n","hausdorfs = []\n","per_catogory_jaccards = []\n","jaccards = []\n","\n","#identify the evaluation matrix for the test samples\n","for sliced_nii_file in sliced_nii_files:\n","\n","    if not predicted:\n","        # print(\"if not predicted executed\")\n","        # Create the output filenames\n","        sample_name = os.path.basename(sliced_nii_file)\n","        pred_filename = os.path.join(pred_save_dir, \"pred\" + sample_name)\n","        # Load the 2D NIfTI file and returns nifti, numpy and sitk prediction\n","        # print(sliced_nii_file)\n","        pred_nifti, pred = mr_lax_inference(unet, sliced_nii_file)\n","        pred = np.transpose(pred, (1, 2, 3, 0))\n","        # print(\"pred shape:\", pred.shape)\n","        # Save the predicted output as a NIfTI file\n","        nib.save(pred_nifti, pred_filename)\n","\n","        pred_sitk = sitk.ReadImage(pred_filename)\n","\n","        # pred = np.transpose(pred, (1, 2, 3, 0))\n","    else:\n","        # print(\"else executed\")\n","        sample_name = os.path.basename(sliced_nii_file)\n","        pred_filename = os.path.join(pred_load_dir, \"pred\" + sample_name)\n","        pred_nifti = nib.load(pred_filename)\n","        pred = pred_nifti.get_fdata()\n","        pred_sitk = sitk.ReadImage(pred_filename)\n","        pred = np.expand_dims(pred, axis=-1)\n","\n","    ground_truth_file = os.path.join(ground_truth_dir, sample_name)\n","    ground_truth = nib.load(ground_truth_file)\n","    # print(\"ground truth shape:\", ground_truth.shape)\n","    ground_truth_sitk = sitk.ReadImage(ground_truth_file)\n","\n","    ground_truth = ground_truth.get_fdata()\n","    num_labels = 3\n","\n","    #calculate the evaluation metrics and record them\n","    total_dice_score = dice_score(ground_truth, pred, num_labels)\n","    # print(total_dice_score)\n","    per_catogory_jaccard = []\n","    per_catogory_jaccard, jaccard = jaccard_score(ground_truth, pred)\n","    hausdorf_distance = hausdorf(ground_truth_sitk, pred_sitk)\n","    # per_category_accuracy, overall_acc = segmentation_accuracy(ground_truth, pred)\n","\n","    dice_scores.append(total_dice_score)\n","    hausdorfs.append(hausdorf_distance)\n","    per_catogory_jaccards.append(per_catogory_jaccard)\n","    jaccards.append(jaccard)\n","\n","\n","print(\"Dice scores:\", dice_scores)\n","mean_dice =  np.mean(dice_scores)\n","print(\"Mean Dice Score:\", mean_dice)\n","\n","print(\"Hausdorf distances:\", hausdorfs)\n","mean_haus =  np.mean(hausdorfs)\n","print(\"Mean Hausdorf distance:\", mean_haus)\n","\n","print(\"per cat accuracies:\", per_catogory_jaccards)\n","mean_cat_jac =  np.mean(per_catogory_jaccards)\n","print(\"Mean per cat jaccard score:\", mean_cat_jac)\n"]},{"cell_type":"markdown","metadata":{"id":"w9aD_52dpKHs"},"source":["# Save dice scores & Hausdorf distance as CSV data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gpotIC-Fpf2g"},"outputs":[],"source":["import csv\n","# Path to the CSV file\n","csv_file_path = os.path.join(pred_save_dir, 'eva_metrics.csv')\n","\n","# Write the eva metrics to the CSV file\n","# Write the evaluation metrics to the CSV file\n","with open(csv_file_path, mode=\"w\", newline=\"\") as csv_file:\n","    writer = csv.writer(csv_file)\n","    header = [\"Dice Score\", \"Hausdorff Distance\"]\n","    max_categories = 2\n","    # Add per-category accuracy column headers\n","    for i in range(max_categories):\n","        header.append(f\"Category {i+1} Jaccard\")\n","\n","    header.append(\"Overall Accuracy\")\n","    writer.writerow(header)  # Write the header\n","\n","    for dice, hausdorff, category_jaccards, overall_jac in zip(dice_scores, hausdorfs, per_catogory_jaccards, jaccards):\n","        row = [dice, hausdorff]\n","\n","        # Fill in per-category accuracy values\n","        row.extend(category_jaccards)\n","\n","        # Fill in any remaining columns with None\n","        num_missing = max_categories - len(category_jaccards)\n","        row.extend([None] * num_missing)\n","\n","        row.append(overall_jac)\n","        writer.writerow(row)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4630,"status":"ok","timestamp":1692809855801,"user":{"displayName":"Zifeng Wang (George)","userId":"11537422646774520818"},"user_tz":-60},"id":"YEK9I-asaSeO","outputId":"635b00ac-1b56-4bae-b439-0fb9206b7524"},"outputs":[{"name":"stdout","output_type":"stream","text":["ground truth shape: (128, 128, 64, 1)\n","pred output shape: (128, 128, 64)\n","Requirement already satisfied: SimpleITK in /usr/local/lib/python3.10/dist-packages (2.2.1)\n","prediction shape: (128, 128, 64)\n","5.151650428771973\n"]}],"source":["from scipy.spatial.distance import cdist\n","\n","pred_save_dir = '/content/gdrive/My Drive/pred_output/pred_4.nii.gz'\n","ground_truth_dir = '/content/gdrive/My Drive/crop_preprocessed_bai/test_3D/crop_14AB01345_segmentation_ES.nii.gz'\n","\n","# pred_save_dir = '/content/gdrive/My Drive/pred_output/08-23_16-15/predcrop_14CR01440_segmentation_ES.nii.gz'\n","# ground_truth_dir = '/content/gdrive/My Drive/crop_preprocessed_bai/test_3D/crop_14CR01440_segmentation_ED.nii.gz'\n","\n","\n","ground_truth = nib.load(ground_truth_dir)\n","pred_output = nib.load(pred_save_dir)\n","\n","# Extract the image data as a NumPy array\n","ground_truth = ground_truth.get_fdata()\n","pred_output = pred_output.get_fdata()\n","\n","print(\"ground truth shape:\", ground_truth.shape)\n","print(\"pred output shape:\", pred_output.shape)\n","# from functools import partial\n","\n","import numpy as np\n","!pip install SimpleITK\n","import SimpleITK as sitk\n","from SimpleITK import GetArrayViewFromImage as ArrayView\n","\n","prediction = sitk.ReadImage('/content/gdrive/My Drive/pred_output/pred_4.nii.gz')\n","gold = sitk.ReadImage('/content/gdrive/My Drive/crop_preprocessed_bai/test_3D/crop_14AB01345_segmentation_ES.nii.gz')\n","\n","# prediction = sitk.ReadImage('/content/gdrive/My Drive/pred_output/08-23_16-15/predcrop_14CR01440_segmentation_ES.nii.gz')\n","# gold = sitk.ReadImage('/content/gdrive/My Drive/crop_preprocessed_bai/test_3D/crop_14CR01440_segmentation_ED.nii.gz')\n","\n","print(\"prediction shape:\", prediction.GetSize())\n","\n","distance_map = partial(sitk.SignedMaurerDistanceMap, squaredDistance=False, useImageSpacing=True)\n","\n","\n","def hausdorf(gold, prediction, num_labels = 1):\n","    for label in range(1, num_labels + 1):\n","        gold_surface = sitk.LabelContour(gold == label, False)\n","        prediction_surface = sitk.LabelContour(prediction == label, False)\n","\n","        ### Get distance map for contours (the distance map computes the minimum distances)\n","        prediction_distance_map = sitk.Abs(distance_map(prediction_surface))\n","        gold_distance_map = sitk.Abs(distance_map(gold_surface))\n","\n","        ### Find the distances to surface points of the contour.  Calculate in both directions\n","        gold_to_prediction = ArrayView(prediction_distance_map)[ArrayView(gold_surface) == 1]\n","        prediction_to_gold = ArrayView(gold_distance_map)[ArrayView(prediction_surface) == 1]\n","\n","        ### Find the 95% Distance for each direction and average\n","\n","        hausdorf = (np.percentile(prediction_to_gold, 95) + np.percentile(gold_to_prediction, 95)) / 2.0\n","        return hausdorf\n","print(hausdorf(gold, prediction))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wZeLE0qZjd2j"},"outputs":[],"source":["### Insert your code ###\n","image_test_1 = imageio.imread('Task01_BrainTumour_2D/test_images/BRATS_004_z62.png')\n","image_test_2 = imageio.imread('Task01_BrainTumour_2D/test_images/BRATS_016_z62.png')\n","image_test_3 = imageio.imread('Task01_BrainTumour_2D/test_images/BRATS_058_z93.png')\n","image_test_4 = imageio.imread('Task01_BrainTumour_2D/test_images/BRATS_115_z62.png')\n","\n","label_test_1 = imageio.imread('Task01_BrainTumour_2D/test_labels/BRATS_004_z62.png')\n","label_test_2 = imageio.imread('Task01_BrainTumour_2D/test_labels/BRATS_016_z62.png')\n","label_test_3 = imageio.imread('Task01_BrainTumour_2D/test_labels/BRATS_058_z93.png')\n","label_test_4 = imageio.imread('Task01_BrainTumour_2D/test_labels/BRATS_115_z62.png')\n","\n","image_test_1_3D, image_test_2_3D, image_test_3_3D, image_test_4_3D = np.expand_dims(image_test_1, axis=(0,1)), np.expand_dims(image_test_2, axis=(0,1)), np.expand_dims(image_test_3, axis=(0,1)), np.expand_dims(image_test_4, axis=(0,1))\n","image_test_1_tor, image_test_2_tor, image_test_3_tor, image_test_4_tor = torch.from_numpy(image_test_1_3D), torch.from_numpy(image_test_2_3D), torch.from_numpy(image_test_3_3D), torch.from_numpy(image_test_4_3D)\n","image_test_1_tor, image_test_2_tor, image_test_3_tor, image_test_4_tor = image_test_1_tor.to(device, dtype=torch.float32), image_test_2_tor.to(device, dtype=torch.float32), image_test_3_tor.to(device, dtype=torch.float32), image_test_4_tor.to(device, dtype=torch.float32)\n","\n","pred_test_1 = np.argmax((model(image_test_1_tor).detach().reshape((4,120,120))), 0)\n","pred_test_2 = np.argmax((model(image_test_2_tor).detach().reshape((4,120,120))), 0)\n","pred_test_3 = np.argmax((model(image_test_3_tor).detach().reshape((4,120,120))), 0)\n","pred_test_4 = np.argmax((model(image_test_4_tor).detach().reshape((4,120,120))), 0)\n","\n","fig = plt.figure(figsize=(50, 50))\n","\n","fig.add_subplot(4, 3, 1)\n","plt.imshow(image_test_1, cmap='gray')\n","plt.axis('off')\n","plt.gcf().set_size_inches(10, 10)\n","\n","fig.add_subplot(4, 3, 2)\n","plt.imshow(pred_test_1, cmap = colors.ListedColormap(['black', 'green', 'blue', 'red']))\n","plt.axis('off')\n","plt.gcf().set_size_inches(10, 10)\n","\n","fig.add_subplot(4, 3, 3)\n","plt.imshow(label_test_1, cmap = colors.ListedColormap(['black', 'green', 'blue', 'red']))\n","plt.axis('off')\n","plt.gcf().set_size_inches(10, 10)\n","\n","\n","fig.add_subplot(4, 3, 4)\n","plt.imshow(image_test_2, cmap='gray')\n","plt.axis('off')\n","plt.gcf().set_size_inches(10, 10)\n","\n","fig.add_subplot(4, 3, 5)\n","plt.imshow(pred_test_2, cmap = colors.ListedColormap(['black', 'green', 'blue', 'red']))\n","plt.axis('off')\n","plt.gcf().set_size_inches(10, 10)\n","\n","fig.add_subplot(4, 3, 6)\n","plt.imshow(label_test_2, cmap = colors.ListedColormap(['black', 'green', 'blue', 'red']))\n","plt.axis('off')\n","plt.gcf().set_size_inches(10, 10)\n","\n","\n","fig.add_subplot(4, 3, 7)\n","plt.imshow(image_test_3, cmap='gray')\n","plt.axis('off')\n","plt.gcf().set_size_inches(10, 10)\n","\n","fig.add_subplot(4, 3, 8)\n","plt.imshow(pred_test_3, cmap = colors.ListedColormap(['black', 'green', 'blue', 'red']))\n","plt.axis('off')\n","plt.gcf().set_size_inches(10, 10)\n","\n","fig.add_subplot(4, 3, 9)\n","plt.imshow(label_test_3, cmap = colors.ListedColormap(['black', 'green', 'blue', 'red']))\n","plt.axis('off')\n","plt.gcf().set_size_inches(10, 10)\n","\n","\n","fig.add_subplot(4, 3, 10)\n","plt.imshow(image_test_4, cmap='gray')\n","plt.axis('off')\n","plt.gcf().set_size_inches(10, 10)\n","\n","fig.add_subplot(4, 3, 11)\n","plt.imshow(pred_test_4, cmap = colors.ListedColormap(['black', 'green', 'blue', 'red']))\n","plt.axis('off')\n","plt.gcf().set_size_inches(10, 10)\n","\n","fig.add_subplot(4, 3, 12)\n","plt.imshow(label_test_4, cmap = colors.ListedColormap(['black', 'green', 'blue', 'red']))\n","plt.axis('off')\n","plt.gcf().set_size_inches(10, 10)\n","\n","\n","### End of your code ###"]}],"metadata":{"celltoolbar":"Slideshow","colab":{"machine_shape":"hm","toc_visible":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}