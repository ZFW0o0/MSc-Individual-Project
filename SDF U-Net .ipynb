{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26281,"status":"ok","timestamp":1694036588956,"user":{"displayName":"Zifeng Wang (George)","userId":"11537422646774520818"},"user_tz":-60},"id":"Ohfg9Iyp0za_","outputId":"d33527e0-bb9a-4967-9b88-ada00c5eb5be"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount(\"/content/gdrive\")"]},{"cell_type":"markdown","metadata":{"id":"PVk5nrEtumqN"},"source":["# Import libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"flwBUgHCumMU"},"outputs":[],"source":["# Import libraries\n","import tarfile\n","import imageio\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset\n","import numpy as np\n","import time\n","import os\n","import random\n","import matplotlib.pyplot as plt\n","from matplotlib import colors\n","import imageio.v2 as imageio\n","\n","import nibabel as nib\n","from tqdm import tqdm\n","import glob\n","import shutil\n","import keras\n","from torch.utils.tensorboard import SummaryWriter\n","\n","from scipy.ndimage import distance_transform_edt"]},{"cell_type":"markdown","metadata":{"id":"-W8RZyHxuZwf"},"source":["# convert medical image into SDF volume"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w7oVnjrXG9Oj"},"outputs":[],"source":["import math\n","input_dir_bai = '/content/gdrive/My Drive/crop_preprocessed_bai/train_3D'\n","output_dir = '/content/gdrive/My Drive/sdf_preprocessed_bai/train_3D'\n","\n","os.makedirs(output_dir, exist_ok=True)\n","\n","nii_files = glob.glob(os.path.join(input_dir_bai, \"*.nii.gz\"))\n","\n","#apply cropping to the images and save the cropped images to output_dir\n","for nii_file in nii_files:\n","    img = nib.load(nii_file)\n","    x, y, z, c = img.shape\n","    data = img.get_fdata()\n","\n","    lv_mask = (data == 1)\n","    myo_mask = (data == 2)\n","\n","    SDF_lv = distance_transform_edt(lv_mask)\n","    SDF_myo = distance_transform_edt(myo_mask)\n","\n","    # stack the two SDF volumes\n","    SDF_stacked = np.stack((SDF_lv, SDF_myo), axis=-1)\n","    SDF_stacked = SDF_stacked.squeeze()\n","\n","    # Create the output filenames\n","    sample_name = os.path.basename(nii_file)\n","    sdf_filename = os.path.join(output_dir, sample_name)\n","\n","    # Save the sliced long axis views as a NIfTI file\n","    sdf_img = nib.Nifti1Image(SDF_stacked, img.affine)\n","    nib.save(sdf_img, sdf_filename)\n","\n","\n","input_dir_bai = '/content/gdrive/My Drive/crop_preprocessed_bai/test_3D'\n","output_dir = '/content/gdrive/My Drive/sdf_preprocessed_bai/test_3D'\n","\n","os.makedirs(output_dir, exist_ok=True)\n","\n","nii_files = glob.glob(os.path.join(input_dir_bai, \"*.nii.gz\"))\n","\n","#apply cropping to the images and save the cropped images to output_dir\n","for nii_file in nii_files:\n","    img = nib.load(nii_file)\n","    x, y, z, c = img.shape\n","    data = img.get_fdata()\n","\n","    lv_mask = (data == 1)\n","    myo_mask = (data == 2)\n","\n","    SDF_lv = distance_transform_edt(lv_mask)\n","    SDF_myo = distance_transform_edt(myo_mask)\n","\n","    # stack the two SDF volumes\n","    SDF_stacked = np.stack((SDF_lv, SDF_myo), axis=-1)\n","    SDF_stacked = SDF_stacked.squeeze()\n","\n","    # Create the output filenames\n","    sample_name = os.path.basename(nii_file)\n","    sdf_filename = os.path.join(output_dir, sample_name)\n","\n","    # Save the sliced long axis views as a NIfTI file\n","    sdf_img = nib.Nifti1Image(SDF_stacked, img.affine)\n","    nib.save(sdf_img, sdf_filename)\n"]},{"cell_type":"markdown","metadata":{"id":"If5REy7y9TYL"},"source":["# Dataset loading class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VwsmmbWG9T5-"},"outputs":[],"source":["class CardiacImageSet(keras.utils.Sequence):\n","    \"\"\" Cardiac image set \"\"\"\n","    def __init__(self, image_path, label_path='', deploy=False):\n","        self.image_path = image_path\n","        self.deploy = deploy\n","        self.images = []\n","        self.labels = []\n","\n","        image_names = [file for file in os.listdir(image_path) if file.endswith('.nii.gz')]\n","        for image_name in image_names:\n","            # Read the image\n","            image = nib.load(os.path.join(image_path, image_name))\n","            image = image.get_fdata()\n","            #transpose image dimension from XYZC to CXYZ\n","            image = np.transpose(image, (3, 0, 1, 2))\n","            self.images += [image]\n","\n","            # Read the label map\n","            if not self.deploy:\n","                label_name = os.path.join(label_path, image_name)\n","                label = nib.load(label_name)\n","                label = label.get_fdata()\n","                label = np.transpose(label, (3, 0, 1, 2))\n","                self.labels += [label]\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        # Get an image and perform intensity normalisation\n","        # Dimension: XYZ\n","        # image = normalise_intensity(self.images[idx])\n","        image = self.images[idx]\n","\n","        # Get its label map\n","        # Dimension: XYZ\n","        label = self.labels[idx]\n","        return image, label\n","\n","    def get_random_batch(self, batch_size):\n","        # Get a batch of paired images and label maps\n","        # Dimension of images: NCXYZ\n","        # Dimension of labels: NXYZ\n","        images, labels = [], []\n","\n","        ### Insert your code ###\n","        for i in range(batch_size):\n","            #randomly retrieve an image and label map\n","            random_idx = random.randint(0,self.__len__() - 1)\n","            random_image, random_label = self.__getitem__(random_idx)\n","            images += [random_image]\n","            labels += [random_label]\n","\n","        #Turn the list into np array\n","        images = np.array(images)\n","        labels = np.array(labels)\n","        ### End of your code ###\n","        return images, labels\n","\n","    def get_batch(self, batch_size, iteration_num):\n","      images, labels = [], []\n","      batch_num = self.__len__()//batch_size\n","      image_idx = ((iteration_num % batch_num) - 1) * batch_size\n","      for i in range(batch_size):\n","        image, label = self.__getitem__(image_idx + i)\n","        images += [image]\n","        labels += [label]\n","\n","      images = np.array(images)\n","      labels = np.array(labels)\n","      return images, labels\n","\n","# train_set = CardiacImageSet('/content/gdrive/My Drive/crop_preprocessed_bai/train_2D', '/content/gdrive/My Drive/crop_preprocessed_bai/train_3D')\n","# test_set = CardiacImageSet('/content/gdrive/My Drive/crop_preprocessed_bai/test_2D', '/content/gdrive/My Drive/crop_preprocessed_bai/test_3D')\n","\n","# image_1, label_1 = train_set.__getitem__(88)\n","# print(image_1.shape)\n","# print(label_1.shape)\n","\n","# test_images, test_labels = train_set.get_random_batch(4)\n","# print(test_images.shape)\n","# print(test_labels.shape)\n","# print(test_images.dtype)\n"]},{"cell_type":"markdown","metadata":{"id":"XAJ2gYrf0Wcl"},"source":["# Construct SDF U-Net architecture"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1694036622470,"user":{"displayName":"Zifeng Wang (George)","userId":"11537422646774520818"},"user_tz":-60},"id":"Ms0ZHmw-0sSC","outputId":"47b00f5b-32a8-4edc-b51d-d1f763d40f92"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of parameters in the model: 6406626\n"]}],"source":["class UNet3d(nn.Module):\n","    def contracting_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n","        block = torch.nn.Sequential(\n","            torch.nn.Conv3d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=1),\n","            torch.nn.LeakyReLU(0.1),\n","            torch.nn.BatchNorm3d(mid_channel),\n","            torch.nn.Conv3d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=out_channels, padding=1),\n","            torch.nn.LeakyReLU(0.1),\n","            torch.nn.BatchNorm3d(out_channels),\n","        )\n","        return block\n","\n","    def expansive_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n","        block = torch.nn.Sequential(\n","            torch.nn.Conv3d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=1),\n","            torch.nn.LeakyReLU(0.1),\n","            torch.nn.BatchNorm3d(mid_channel),\n","            torch.nn.Conv3d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel, padding=1),\n","            torch.nn.LeakyReLU(0.1),\n","            torch.nn.BatchNorm3d(mid_channel),\n","            torch.nn.ConvTranspose3d(in_channels=mid_channel, out_channels=out_channels, kernel_size=3, stride=2,\n","                                     padding=1, output_padding=1)\n","        )\n","        return block\n","\n","    def final_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n","        block = torch.nn.Sequential(\n","            torch.nn.Conv3d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=1),\n","            torch.nn.LeakyReLU(0.1),\n","            torch.nn.BatchNorm3d(mid_channel),\n","            torch.nn.Conv3d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel, padding=1),\n","            torch.nn.LeakyReLU(0.1),\n","            torch.nn.BatchNorm3d(mid_channel),\n","            torch.nn.Conv3d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=out_channels, padding=1),\n","            # torch.nn.Sigmoid()\n","        )\n","        return block\n","\n","    def __init__(self, in_channel, out_channel):\n","        super(UNet3d, self).__init__()\n","        # Encode\n","        self.conv_encode1 = self.contracting_block(in_channel, 16, 32)\n","        self.conv_maxpool1 = torch.nn.MaxPool3d(kernel_size=2)\n","        self.conv_encode2 = self.contracting_block(32, 32, 64)\n","        self.conv_maxpool2 = torch.nn.MaxPool3d(kernel_size=2)\n","        self.conv_encode3 = self.contracting_block(64, 64, 128)\n","        self.conv_maxpool3 = torch.nn.MaxPool3d(kernel_size=2)\n","        # Bottleneck\n","        self.bottleneck = torch.nn.Sequential(\n","            torch.nn.Conv3d(kernel_size=3, in_channels=128, out_channels=128, padding=1),\n","            torch.nn.LeakyReLU(0.1),\n","            torch.nn.BatchNorm3d(128),\n","            torch.nn.Conv3d(kernel_size=3, in_channels=128, out_channels=256, padding=1),\n","            torch.nn.LeakyReLU(0.1),\n","            torch.nn.BatchNorm3d(256),\n","            torch.nn.ConvTranspose3d(in_channels=256, out_channels=256, kernel_size=3, stride=2, padding=1,\n","                                     output_padding=1)\n","        )\n","        # Decode\n","        self.conv_decode3 = self.expansive_block(128+256, 128, 128)\n","        self.conv_decode2 = self.expansive_block(64+128, 64, 64)\n","        self.final_layer = self.final_block(32+64, 32, out_channel)\n","\n","    def crop_and_concat(self, upsampled, bypass, crop=False):\n","        if crop:\n","            c = (bypass.size()[2] - upsampled.size()[2]) // 2\n","            bypass = F.pad(bypass, (-c, -c, -c, -c))\n","        # print(\"unsampled shape:\", upsampled.shape)\n","        # print(\"bypass shape:\", bypass.shape)\n","\n","        return torch.cat((upsampled, bypass), 1)\n","\n","    def forward(self, x):\n","        # Encode\n","        encode_block1 = self.conv_encode1(x)\n","        encode_pool1 = self.conv_maxpool1(encode_block1)\n","        encode_block2 = self.conv_encode2(encode_pool1)\n","        encode_pool2 = self.conv_maxpool2(encode_block2)\n","        encode_block3 = self.conv_encode3(encode_pool2)\n","        encode_pool3 = self.conv_maxpool3(encode_block3)\n","        # Bottleneck\n","        bottleneck1 = self.bottleneck(encode_pool3)\n","        # Decode\n","        decode_block3 = self.crop_and_concat(bottleneck1, encode_block3, crop=False)\n","        cat_layer2 = self.conv_decode3(decode_block3)\n","        decode_block2 = self.crop_and_concat(cat_layer2, encode_block2, crop=False)\n","        cat_layer1 = self.conv_decode2(decode_block2)\n","        decode_block1 = self.crop_and_concat(cat_layer1, encode_block1, crop=False)\n","        final_layer = self.final_layer(decode_block1)\n","        return final_layer\n","\n","    def count_parameters(self):\n","        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n","\n","\n","toy_model = UNet3d(in_channel=1, out_channel=2)\n","total_parameters = toy_model.count_parameters()\n","print(\"Total number of parameters in the model:\", total_parameters)"]},{"cell_type":"markdown","metadata":{"id":"k9O_V0w30yRw"},"source":["# Model Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2362704,"status":"ok","timestamp":1694038986141,"user":{"displayName":"Zifeng Wang (George)","userId":"11537422646774520818"},"user_tz":-60},"id":"J_m0pyO10143","outputId":"1be814cd-c0c8-4683-f5f5-b9e455bd782e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cuda\n","training loss for epoch 1.0:\n","0.16900870203971863\n","test loss for epoch 1.0:\n","0.7079792022705078\n","training loss for epoch 2.0:\n","0.0798821821808815\n","test loss for epoch 2.0:\n","0.1769847422838211\n","training loss for epoch 3.0:\n","0.07263513654470444\n","test loss for epoch 3.0:\n","0.06357325613498688\n","training loss for epoch 4.0:\n","0.06941662728786469\n","test loss for epoch 4.0:\n","0.05312737077474594\n","training loss for epoch 5.0:\n","0.06851514428853989\n","test loss for epoch 5.0:\n","0.10315446555614471\n","training loss for epoch 6.0:\n","0.06548455357551575\n","test loss for epoch 6.0:\n","0.25690215826034546\n","training loss for epoch 7.0:\n","0.0641406923532486\n","test loss for epoch 7.0:\n","0.09746898710727692\n","training loss for epoch 8.0:\n","0.0610945001244545\n","test loss for epoch 8.0:\n","0.07260861992835999\n","training loss for epoch 9.0:\n","0.0583309531211853\n","test loss for epoch 9.0:\n","0.04948240518569946\n","training loss for epoch 10.0:\n","0.05854983255267143\n","test loss for epoch 10.0:\n","0.037719469517469406\n","training loss for epoch 11.0:\n","0.05659528449177742\n","test loss for epoch 11.0:\n","0.0419594906270504\n","training loss for epoch 12.0:\n","0.055976565927267075\n","test loss for epoch 12.0:\n","0.07724159955978394\n","training loss for epoch 13.0:\n","0.056395675987005234\n","test loss for epoch 13.0:\n","0.03664659708738327\n","training loss for epoch 14.0:\n","0.05509514361619949\n","test loss for epoch 14.0:\n","1.4577516317367554\n","training loss for epoch 15.0:\n","0.05156667158007622\n","test loss for epoch 15.0:\n","0.05549922585487366\n","training loss for epoch 16.0:\n","0.04767906665802002\n","test loss for epoch 16.0:\n","0.04868631064891815\n","training loss for epoch 17.0:\n","0.04611000046133995\n","test loss for epoch 17.0:\n","5.266152858734131\n","training loss for epoch 18.0:\n","0.044919710606336594\n","test loss for epoch 18.0:\n","0.02400403469800949\n","training loss for epoch 19.0:\n","0.044679056853055954\n","test loss for epoch 19.0:\n","0.06590033322572708\n","training loss for epoch 20.0:\n","0.04340265318751335\n","test loss for epoch 20.0:\n","0.025624411180615425\n","training loss for epoch 21.0:\n","0.041303861886262894\n","test loss for epoch 21.0:\n","6.260503768920898\n","training loss for epoch 22.0:\n","0.035646114498376846\n","test loss for epoch 22.0:\n","14.472480773925781\n","training loss for epoch 23.0:\n","0.04475608468055725\n","test loss for epoch 23.0:\n","0.06970428675413132\n","training loss for epoch 24.0:\n","0.03398817405104637\n","test loss for epoch 24.0:\n","16.4074649810791\n","training loss for epoch 25.0:\n","0.03562452644109726\n","test loss for epoch 25.0:\n","0.023436032235622406\n","training loss for epoch 26.0:\n","0.030326416715979576\n","test loss for epoch 26.0:\n","0.027828408405184746\n","training loss for epoch 27.0:\n","0.02498871646821499\n","test loss for epoch 27.0:\n","0.022489352151751518\n","training loss for epoch 28.0:\n","0.022503918036818504\n","test loss for epoch 28.0:\n","0.021522101014852524\n","training loss for epoch 29.0:\n","0.0213443785905838\n","test loss for epoch 29.0:\n","0.015713565051555634\n","training loss for epoch 30.0:\n","0.021993709728121758\n","test loss for epoch 30.0:\n","14.36601448059082\n","training loss for epoch 31.0:\n","0.022514978423714638\n","test loss for epoch 31.0:\n","3.015017509460449\n","training loss for epoch 32.0:\n","0.026223255321383476\n","test loss for epoch 32.0:\n","0.01648836024105549\n","training loss for epoch 33.0:\n","0.02142166905105114\n","test loss for epoch 33.0:\n","0.022606730461120605\n","training loss for epoch 34.0:\n","0.018516192212700844\n","test loss for epoch 34.0:\n","0.0212608240544796\n","training loss for epoch 35.0:\n","0.019614869728684425\n","test loss for epoch 35.0:\n","0.022393405437469482\n","training loss for epoch 36.0:\n","0.018438486382365227\n","test loss for epoch 36.0:\n","0.01410607062280178\n","training loss for epoch 37.0:\n","0.01705383136868477\n","test loss for epoch 37.0:\n","0.012155595235526562\n","training loss for epoch 38.0:\n","0.017081432044506073\n","test loss for epoch 38.0:\n","0.01761053502559662\n","training loss for epoch 39.0:\n","0.016075892373919487\n","test loss for epoch 39.0:\n","0.017109880223870277\n","training loss for epoch 40.0:\n","0.016091512516140938\n","test loss for epoch 40.0:\n","0.036954671144485474\n","training loss for epoch 41.0:\n","0.01696942187845707\n","test loss for epoch 41.0:\n","0.03995673730969429\n","training loss for epoch 42.0:\n","0.018811916932463646\n","test loss for epoch 42.0:\n","0.906527042388916\n","training loss for epoch 43.0:\n","0.016597149893641472\n","test loss for epoch 43.0:\n","0.022941991686820984\n","training loss for epoch 44.0:\n","0.015640420839190483\n","test loss for epoch 44.0:\n","0.01619080826640129\n","training loss for epoch 45.0:\n","0.015996156260371208\n","test loss for epoch 45.0:\n","0.02277155965566635\n","training loss for epoch 46.0:\n","0.016368240118026733\n","test loss for epoch 46.0:\n","0.05467688664793968\n","training loss for epoch 47.0:\n","0.018009759485721588\n","test loss for epoch 47.0:\n","0.015931714326143265\n","training loss for epoch 48.0:\n","0.02083098702132702\n","test loss for epoch 48.0:\n","0.02537633664906025\n","training loss for epoch 49.0:\n","0.019959615543484688\n","test loss for epoch 49.0:\n","1.0790554285049438\n","training loss for epoch 50.0:\n","0.018204646185040474\n","test loss for epoch 50.0:\n","1.2339930534362793\n","training loss for epoch 51.0:\n","0.01943904347717762\n","test loss for epoch 51.0:\n","0.8123178482055664\n","training loss for epoch 52.0:\n","0.02483937330543995\n","test loss for epoch 52.0:\n","0.019669916480779648\n","training loss for epoch 53.0:\n","0.02450764738023281\n","test loss for epoch 53.0:\n","0.040419213473796844\n","training loss for epoch 54.0:\n","0.018869763240218163\n","test loss for epoch 54.0:\n","0.0199432410299778\n","training loss for epoch 55.0:\n","0.017903968691825867\n","test loss for epoch 55.0:\n","0.016715697944164276\n","training loss for epoch 56.0:\n","0.016674451529979706\n","test loss for epoch 56.0:\n","0.019608482718467712\n","training loss for epoch 57.0:\n","0.01635744422674179\n","test loss for epoch 57.0:\n","0.01821083202958107\n","training loss for epoch 58.0:\n","0.016343416646122932\n","test loss for epoch 58.0:\n","0.018376057967543602\n","training loss for epoch 59.0:\n","0.015505126677453518\n","test loss for epoch 59.0:\n","0.02223833277821541\n","training loss for epoch 60.0:\n","0.013872559182345867\n","test loss for epoch 60.0:\n","0.02862432599067688\n","training loss for epoch 61.0:\n","0.013438986614346504\n","test loss for epoch 61.0:\n","0.014616996049880981\n","training loss for epoch 62.0:\n","0.014853114262223244\n","test loss for epoch 62.0:\n","0.016494765877723694\n","training loss for epoch 63.0:\n","0.012217335402965546\n","test loss for epoch 63.0:\n","0.016952943056821823\n","training loss for epoch 64.0:\n","0.012638531625270844\n","test loss for epoch 64.0:\n","0.022707805037498474\n","training loss for epoch 65.0:\n","0.01267386507242918\n","test loss for epoch 65.0:\n","0.016458779573440552\n","training loss for epoch 66.0:\n","0.012351742945611477\n","test loss for epoch 66.0:\n","0.022882744669914246\n","training loss for epoch 67.0:\n","0.012380960397422314\n","test loss for epoch 67.0:\n","0.07516346871852875\n","training loss for epoch 68.0:\n","0.012800589203834534\n","test loss for epoch 68.0:\n","0.03877434879541397\n","training loss for epoch 69.0:\n","0.013165733776986599\n","test loss for epoch 69.0:\n","0.023113220930099487\n","training loss for epoch 70.0:\n","0.014809250831604004\n","test loss for epoch 70.0:\n","0.14167271554470062\n","training loss for epoch 71.0:\n","0.012700514867901802\n","test loss for epoch 71.0:\n","1.0664634704589844\n","training loss for epoch 72.0:\n","0.012325051240622997\n","test loss for epoch 72.0:\n","0.6369947791099548\n","training loss for epoch 73.0:\n","0.015266649425029755\n","test loss for epoch 73.0:\n","0.018578188493847847\n","training loss for epoch 74.0:\n","0.016412900760769844\n","test loss for epoch 74.0:\n","0.018718358129262924\n","training loss for epoch 75.0:\n","0.016868049278855324\n","test loss for epoch 75.0:\n","0.029560130089521408\n","training loss for epoch 76.0:\n","0.017110057175159454\n","test loss for epoch 76.0:\n","0.018618512898683548\n","training loss for epoch 77.0:\n","0.013607156462967396\n","test loss for epoch 77.0:\n","1.593912124633789\n","training loss for epoch 78.0:\n","0.013799116015434265\n","test loss for epoch 78.0:\n","0.020504670217633247\n","training loss for epoch 79.0:\n","0.012720376253128052\n","test loss for epoch 79.0:\n","1.1196848154067993\n","training loss for epoch 80.0:\n","0.012583928182721138\n","test loss for epoch 80.0:\n","0.02422815002501011\n","training loss for epoch 81.0:\n","0.013308294117450714\n","test loss for epoch 81.0:\n","0.01704266294836998\n","training loss for epoch 82.0:\n","0.014264917932450771\n","test loss for epoch 82.0:\n","0.8963843584060669\n","training loss for epoch 83.0:\n","0.011992848478257656\n","test loss for epoch 83.0:\n","0.025244902819395065\n","training loss for epoch 84.0:\n","0.012392548844218254\n","test loss for epoch 84.0:\n","1.2639490365982056\n","training loss for epoch 85.0:\n","0.012345685623586178\n","test loss for epoch 85.0:\n","0.7395563125610352\n","training loss for epoch 86.0:\n","0.022430023178458214\n","test loss for epoch 86.0:\n","0.02783500775694847\n","training loss for epoch 87.0:\n","0.014826253056526184\n","test loss for epoch 87.0:\n","0.817428469657898\n","training loss for epoch 88.0:\n","0.012009313330054283\n","test loss for epoch 88.0:\n","0.018353505060076714\n","training loss for epoch 89.0:\n","0.014727617613971233\n","test loss for epoch 89.0:\n","0.02706664800643921\n","training loss for epoch 90.0:\n","0.012667715549468994\n","test loss for epoch 90.0:\n","0.03322186321020126\n","training loss for epoch 91.0:\n","0.012218451127409935\n","test loss for epoch 91.0:\n","0.032419636845588684\n","training loss for epoch 92.0:\n","0.012859332375228405\n","test loss for epoch 92.0:\n","0.023810457438230515\n","training loss for epoch 93.0:\n","0.012012174353003502\n","test loss for epoch 93.0:\n","0.04431745409965515\n","training loss for epoch 94.0:\n","0.012272771447896957\n","test loss for epoch 94.0:\n","0.040906958281993866\n","training loss for epoch 95.0:\n","0.012828980572521687\n","test loss for epoch 95.0:\n","0.9744619131088257\n","training loss for epoch 96.0:\n","0.01595778577029705\n","test loss for epoch 96.0:\n","0.014607973396778107\n","training loss for epoch 97.0:\n","0.013468722812831402\n","test loss for epoch 97.0:\n","0.03659916669130325\n","training loss for epoch 98.0:\n","0.013774019666016102\n","test loss for epoch 98.0:\n","0.02078823372721672\n","training loss for epoch 99.0:\n","0.013652090914547443\n","test loss for epoch 99.0:\n","0.020484216511249542\n","training loss for epoch 100.0:\n","0.012921126559376717\n","test loss for epoch 100.0:\n","0.03265543282032013\n","Training took 2045.608s in total.\n"]}],"source":["# CUDA device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Device: {0}'.format(device))\n","\n","# Build the model\n","num_class = 2\n","model = UNet3d(in_channel=1, out_channel=num_class)\n","model = model.to(device)\n","params = list(model.parameters())\n","\n","model_dir = '/content/gdrive/My Drive/saved_model/SDF-2'\n","if not os.path.exists(model_dir):\n","    os.makedirs(model_dir)\n","\n","# Optimizer\n","optimizer = optim.Adam(params, lr=1e-3)\n","\n","# Segmentation loss\n","criterion = nn.MSELoss()\n","\n","train_image_folder = '/content/gdrive/My Drive/crop_preprocessed_bai/train_2D'\n","train_label_folder = '/content/gdrive/My Drive/sdf_preprocessed_bai/train_3D'\n","test_image_folder = '/content/gdrive/My Drive/crop_preprocessed_bai/test_2D'\n","test_label_folder = '/content/gdrive/My Drive/sdf_preprocessed_bai/test_3D'\n","\n","# Datasets\n","train_set = CardiacImageSet(train_image_folder, train_label_folder)\n","test_set = CardiacImageSet(test_image_folder, test_label_folder)\n","\n","# Create a SummaryWriter object to write TensorBoard logs\n","log_dir = '/content/gdrive/My Drive/tensorboard_logs/SDF'\n","if not os.path.exists(log_dir):\n","    os.makedirs(log_dir)\n","writer = SummaryWriter(log_dir)\n","\n","# Train the model\n","# num_iter = 500\n","train_batch_size = 4\n","eval_batch_size = 4\n","start = time.time()\n","running_loss = 0\n","#number of batches in an epoch\n","num_batches = int(train_set.__len__()/train_batch_size)\n","num_epoch = 100\n","for it in range(1, 1 + (num_batches * num_epoch)):\n","    # Set the modules in training mode, which will have effects on certain modules, e.g. dropout or batchnorm.\n","    start_iter = time.time()\n","    model.train()\n","\n","    # Get a batch of images and labels\n","    images, labels = train_set.get_batch(train_batch_size, it)\n","    images, labels = torch.from_numpy(images), torch.from_numpy(labels)\n","    # image.to() convert the array from system RAM to GPU RAM\n","    images, labels = images.to(device, dtype=torch.float32), labels.to(device, dtype=torch.float32)\n","    #remove the channel dimension in the labels array\n","    labels = labels.squeeze(axis = 1)\n","    # print(\"Images shape:\", images.shape)\n","    logits = model(images)\n","\n","    # Perform optimisation and print out the training loss\n","    # print('logits shape:', logits.shape)\n","    # print('label shape:', labels.shape)\n","\n","    loss = criterion(logits, labels)\n","    running_loss += loss\n","\n","    if it % num_batches == 0:\n","        epoch_loss = running_loss/num_batches\n","        running_loss = 0\n","        print (\"training loss for epoch {}:\".format(it/num_batches))\n","        print(epoch_loss.item())\n","\n","        # Write the training loss to TensorBoard\n","        writer.add_scalar('Loss', epoch_loss.item(), int(it / num_batches))\n","\n","    loss.backward()\n","    optimizer.step()\n","    optimizer.zero_grad()\n","\n","    ###   ###\n","\n","    # Evaluate\n","    if it % num_batches == 0:\n","        model.eval()\n","        # Disabling gradient calculation during reference to reduce memory consumption\n","        with torch.no_grad():\n","            # Evaluate on a batch of test images and print out the test loss\n","            ### Insert your code ###\n","            test_images, test_labels = test_set.get_random_batch(eval_batch_size)\n","            test_images, test_labels = torch.from_numpy(test_images), torch.from_numpy(test_labels)\n","            test_images, test_labels = test_images.to(device, dtype=torch.float32), test_labels.to(device, dtype=torch.long)\n","            test_labels = test_labels.squeeze(axis = 1)\n","            test_logits = model(test_images)\n","            test_loss = criterion(test_logits, test_labels)\n","            print (\"test loss for epoch {}:\".format(it/num_batches))\n","            print(test_loss.item())\n","\n","            # Write the test loss to TensorBoard with a 'test' tag\n","            writer.add_scalar('Loss', test_loss.item(), int(it / num_batches))\n","            ### End of your code ###\n","\n","    # # Save the model\n","    # if it % num_batches == 0:\n","    #     epoch = it/num_batches\n","    #     torch.save(model.state_dict(), os.path.join(model_dir, 'model_{0}.pt'.format(epoch)))\n","print('Training took {:.3f}s in total.'.format(time.time() - start))"]},{"cell_type":"markdown","metadata":{"id":"_doXcq25Zhk8"},"source":["# Prediction generation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-whJhWW1ZoCQ"},"outputs":[],"source":["import datetime\n","\n","device = torch.device(\"cpu\")\n","def model_load():\n","\n","    unet = UNet3d(in_channel=1, out_channel=2)\n","    unet.to(device, dtype=torch.float)\n","\n","    model_list = ['/content/gdrive/My Drive/saved_model/SDF/model_10.0.pt']\n","    model_i = model_list[0]\n","    checkpoint = torch.load(model_i, map_location=torch.device('cpu'))\n","    unet.load_state_dict(checkpoint)\n","    return unet\n","\n","def mr_sdf_inference(unet, slice_img):\n","\n","    img = nib.load(slice_img)\n","    affine = img.affine\n","    data = img.get_fdata()\n","    data = np.transpose(data, (3, 0, 1, 2))\n","\n","    # print(\"sliced image shape:\", data.shape)\n","\n","    data = np.expand_dims(data, axis=(0))\n","\n","    # print(data.shape)\n","\n","    data = torch.from_numpy(data)\n","\n","    # print(data.size())\n","    data = data.to(device, dtype=torch.float32)\n","\n","    # print(data.size())\n","\n","    unet.eval()\n","    output = unet(data)\n","    pred = output.detach().cpu().numpy()\n","\n","    # print(pred.shape)\n","\n","    pred = pred.squeeze()\n","    pred = np.transpose(pred, (1, 2, 3, 0))\n","\n","    distance_field_1 = pred[..., 0]\n","    distance_field_2 = pred[..., 1]\n","\n","    # Create a segmentation map where values greater than 0.5 are labeled accordingly\n","    segmentation_map = np.zeros_like(distance_field_1)\n","\n","    # Label distance field 1 as 1 where distance > 0.5\n","    segmentation_map[distance_field_1 > 0.5] = 1\n","\n","    # Label distance field 2 as 2 where distance > 0.5\n","    segmentation_map[distance_field_2 > 0.5] = 2\n","\n","    # Add a new axis to the segmentation map to make it 128x128x64x1\n","    pred = segmentation_map = np.expand_dims(segmentation_map, axis=-1)\n","\n","    # print(pred.shape)\n","    pred_nifti = nib.Nifti1Image(segmentation_map, affine=affine)\n","\n","    #pred_nifti is a Nifti object, pred is a numpy array\n","    return pred_nifti, pred\n","\n","# sliced_image = '/content/gdrive/My Drive/crop_preprocessed_bai/test_2D/crop_14AB01345_segmentation_ES.nii.gz'\n","# unet = model_load()\n","# pred_nifti, pred = mr_sdf_inference(unet, sliced_image)\n","\n","# pred_save_dir = '/content/gdrive/My Drive/pred_output/SDF/pred_SDF.nii.gz'\n","# nib.save(pred_nifti, pred_save_dir)"]},{"cell_type":"markdown","metadata":{"id":"iG5o8W29xe5Y"},"source":["# Evaluation Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4647,"status":"ok","timestamp":1693591984921,"user":{"displayName":"Zifeng Wang (George)","userId":"11537422646774520818"},"user_tz":-60},"id":"jFCIXjjWxkPx","outputId":"de2ec0c1-5ef7-4045-e62e-b9cbc20beac7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: SimpleITK in /usr/local/lib/python3.10/dist-packages (2.2.1)\n"]}],"source":["from functools import partial\n","\n","import numpy as np\n","!pip install SimpleITK\n","import SimpleITK as sitk\n","from SimpleITK import GetArrayViewFromImage as ArrayView\n","\n","# dice_scores = []\n","def dice_score(ground_truth, predicted, num_labels):\n","    total_intersection = 0\n","    total_gt_count = 0\n","    total_pred_count = 0\n","\n","    for label in range(1, num_labels):  # Start from label 1, assuming label 0 is background\n","        # Create binary masks for the specific label\n","        gt_mask = (ground_truth == label)\n","        pred_mask = (predicted == label)\n","\n","        intersection = np.logical_and(gt_mask, pred_mask).sum()\n","        gt_count = gt_mask.sum()\n","        pred_count = pred_mask.sum()\n","\n","        label_dice = (2.0 * intersection) / (gt_count + pred_count)\n","        # dice_scores.append(label_dice)\n","\n","        total_intersection += intersection\n","        total_gt_count += gt_count\n","        total_pred_count += pred_count\n","\n","    dice = (2.0 * total_intersection) / (total_gt_count + total_pred_count)\n","    return dice\n","\n","distance_map = partial(sitk.SignedMaurerDistanceMap, squaredDistance=False, useImageSpacing=True)\n","def hausdorf(gold, prediction, num_labels = 1):\n","    for label in range(1, num_labels + 1):\n","        gold_surface = sitk.LabelContour(gold == label, False)\n","        prediction_surface = sitk.LabelContour(prediction == label, False)\n","\n","        ### Get distance map for contours (the distance map computes the minimum distances)\n","        prediction_distance_map = sitk.Abs(distance_map(prediction_surface))\n","        gold_distance_map = sitk.Abs(distance_map(gold_surface))\n","\n","        ### Find the distances to surface points of the contour.  Calculate in both directions\n","        gold_to_prediction = ArrayView(prediction_distance_map)[ArrayView(gold_surface) == 1]\n","        prediction_to_gold = ArrayView(gold_distance_map)[ArrayView(prediction_surface) == 1]\n","\n","        ### Find the 95% Distance for each direction and average\n","\n","        hausdorf_dis = (np.percentile(prediction_to_gold, 95) + np.percentile(gold_to_prediction, 95)) / 2.0\n","        return hausdorf_dis\n","\n","def segmentation_accuracy(groundtruth, prediction):\n","    unique_categories = np.unique(groundtruth)\n","    unique_categories = unique_categories[unique_categories != 0]  # Remove background 0\n","\n","    per_category_accuracies = []\n","\n","    for category in unique_categories:\n","        category_mask = (groundtruth == category)\n","        category_pred_mask = (prediction == category)\n","\n","        intersect = np.sum(category_pred_mask * category_mask)\n","        union = np.sum(category_pred_mask) + np.sum(category_mask) - intersect\n","        xor = np.sum(category_mask == category_pred_mask)\n","\n","        category_acc = xor / (union + xor - intersect)\n","        per_category_accuracies.append(category_acc)\n","\n","    overall_intersect = np.sum(prediction * groundtruth)\n","    overall_union = np.sum(prediction) + np.sum(groundtruth) - overall_intersect\n","    overall_xor = np.sum(groundtruth == prediction)\n","\n","    overall_acc = overall_xor / (overall_union + overall_xor - overall_intersect)\n","\n","    return per_category_accuracies, overall_acc\n","\n","\n","\n","def jaccard_score(ground_truth, predicted, num_labels = 3):\n","    \"\"\"\n","    Calculate the Jaccard similarity score (IoU) for multi-label 3D object segmentation.\n","\n","    Parameters:\n","    ground_truth (numpy.ndarray): Ground truth 3D object segmentation (3D binary array).\n","    predicted (numpy.ndarray): Predicted 3D object segmentation (3D binary array).\n","\n","    Returns:\n","    float: Average Jaccard similarity score across all labels.\n","    \"\"\"\n","    # unique_labels = np.unique(np.concatenate((ground_truth, predicted)))\n","    # num_labels = len(unique_labels)\n","    jaccard_scores = np.zeros(num_labels - 1)\n","\n","    for label in range(1, num_labels):\n","        gt_mask = (ground_truth == label)\n","        pred_mask = (predicted == label)\n","\n","        intersection = np.logical_and(gt_mask, pred_mask).sum()\n","        union = np.logical_or(gt_mask, pred_mask).sum()\n","\n","        # intersection = len(list(set(gt_mask).intersection(pred_mask)))\n","        # union = (len(gt_mask) + len(pred_mask)) - intersection\n","\n","        if union == 0:\n","            jaccard_scores[label - 1] = 1.0  # Handle division by zero\n","        else:\n","            jaccard_scores[label - 1] = float(intersection) / union\n","\n","    average_jaccard_score = np.mean(jaccard_scores)\n","    return jaccard_scores, average_jaccard_score\n"]},{"cell_type":"markdown","metadata":{"id":"YwwBWykDxm8z"},"source":["# Visualise Model Output"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":369813,"status":"ok","timestamp":1693592354723,"user":{"displayName":"Zifeng Wang (George)","userId":"11537422646774520818"},"user_tz":-60},"id":"DPuMRM9Wxred","outputId":"89866e44-d7a4-4745-b781-ddd24f9bcbcc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dice scores: [0.9004480691515988, 0.9224785680832434, 0.8855808680630534, 0.8838227318509336, 0.9196916566352891, 0.8615268142095405, 0.9190192857241465, 0.872276237346457, 0.9161947968299309, 0.9102704938159918, 0.8921133000406328, 0.9004477571922674, 0.8883714963761145, 0.9260482189961446, 0.9229819883803514, 0.9062439923367076, 0.867508568252694, 0.9051546831965726, 0.9135940941349213, 0.880861217468509, 0.936171205499479, 0.9197476474112712, 0.9264137760973205, 0.9054669619512484, 0.9066125559565669, 0.88412804967589, 0.9075094707219395, 0.9298547871031257, 0.9125549185816715, 0.9445099646191056, 0.8759668637091301, 0.9320653538325584, 0.9110324703545043, 0.9268823556847686, 0.8426421450643339, 0.9089834190337394, 0.9127319019896726, 0.9122249278499278, 0.8878048780487805, 0.9082516672742479, 0.9161330921104381, 0.9237963794235485, 0.9344575842170803, 0.9108625307527298, 0.892262058582295, 0.8923886314428192, 0.9253039243348014, 0.8957348056575967, 0.9256055100272157, 0.9216528569117673, 0.9192056431349923, 0.8982555831046561, 0.9007973119982374, 0.907393876540882, 0.9273229070837167, 0.891149791615592, 0.9068063165025889, 0.8675275728769368, 0.8981008898654532, 0.9113890986729659, 0.9067410293630784, 0.9214215418261344, 0.9014864921878296, 0.9252431898471378, 0.9233479819356406, 0.9011223144207902, 0.9229645697758496, 0.8951842143484545, 0.947928700399627, 0.8932314015989882, 0.9040841245831132, 0.9029402016949954, 0.9117561963545183, 0.9267331887201735, 0.8745096459784929, 0.9221086702430545, 0.9117941320179622, 0.9145815790528891, 0.9241410121702008, 0.9311359017672632]\n","Mean Dice Score: 0.907684907646086\n","Hausdorf distances: [2.7950849533081055, 2.2499961853027344, 3.053099274635315, 3.4415944814682007, 2.5, 4.215006589889526, 2.4292443990707397, 3.319249391555786, 2.5, 1.8838834762573242, 2.5, 2.5, 2.7950849533081055, 1.2071067690849304, 1.7677669525146484, 2.732178580760956, 4.348855018615723, 2.7950849533081055, 2.4929250836372443, 3.851423501968384, 1.8838872909545898, 2.6475424766540527, 2.133883476257324, 2.732177257537842, 2.5, 3.486232876777649, 2.7950849533081055, 1.9999923706054688, 2.5, 1.7677669525146484, 3.851423501968384, 1.8838796615600586, 2.4122161865234375, 1.7677669525146484, 5.483495235443115, 2.25, 2.3584952354431152, 2.6239516735076904, 3.368548631668091, 2.584634780883789, 2.6475424766540527, 2.0, 2.1792443990707397, 2.5767868757247925, 2.8507786989212036, 2.998322367668152, 1.8838834762573242, 2.9983259439468384, 1.25, 2.4292476177215576, 2.6066524744033757, 2.5, 2.584634780883789, 2.6475424766540527, 2.179240584373474, 2.7321743965148926, 3.3192492723464966, 3.4862316846847534, 3.1160084009170532, 2.669273853302002, 2.1792476177215576, 2.0, 3.4369345903396606, 1.7677669525146484, 2.0, 2.9983235597610474, 2.000011444091797, 2.5, 1.7677669525146484, 2.692110061645508, 2.732179617881775, 2.935411810874939, 2.25, 2.0000076293945312, 3.3192492723464966, 2.0, 2.1792434453964233, 2.4292492866516113, 2.179254651069641, 2.25]\n","Mean Hausdorf distance: 2.596005759388208\n","per cat accuracies: [array([0.89962939, 0.7221449 ]), array([0.88410922, 0.84257156]), array([0.84044867, 0.76931181]), array([0.88756982, 0.6772718 ]), array([0.88176606, 0.83330395]), array([0.86461308, 0.62482797]), array([0.89959087, 0.8213542 ]), array([0.87965066, 0.63712109]), array([0.91127255, 0.76365488]), array([0.88313229, 0.80844048]), array([0.86370201, 0.76735299]), array([0.91058797, 0.7152027 ]), array([0.90181651, 0.64373785]), array([0.91099428, 0.83336983]), array([0.91198193, 0.82681041]), array([0.90751032, 0.7347112 ]), array([0.87280348, 0.59952089]), array([0.90356586, 0.71918877]), array([0.87654046, 0.82286361]), array([0.88609216, 0.65830843]), array([0.9096896 , 0.86518061]), array([0.87948128, 0.83348041]), array([0.88313747, 0.85769333]), array([0.91408184, 0.71782163]), array([0.85065212, 0.81848661]), array([0.88849675, 0.6675807 ]), array([0.91170681, 0.73260805]), array([0.90705549, 0.84470399]), array([0.87615987, 0.82080561]), array([0.9176035 , 0.88594919]), array([0.8664992 , 0.66932794]), array([0.91071089, 0.84792555]), array([0.91330913, 0.75512603]), array([0.91358965, 0.83775148]), array([0.84990289, 0.57147731]), array([0.89880051, 0.78952888]), array([0.86291486, 0.83143725]), array([0.90357432, 0.76292523]), array([0.83609995, 0.77901092]), array([0.92284909, 0.71910211]), array([0.88746617, 0.8215637 ]), array([0.89038896, 0.83533242]), array([0.88550607, 0.87361244]), array([0.87143553, 0.81610686]), array([0.87159512, 0.76447775]), array([0.89760921, 0.67752388]), array([0.91113915, 0.83025885]), array([0.86330724, 0.77534357]), array([0.91627267, 0.83463437]), array([0.88060308, 0.84202298]), array([0.86847826, 0.84152258]), array([0.90625891, 0.69884579]), array([0.90497838, 0.70974849]), array([0.86438126, 0.81418775]), array([0.90595725, 0.8448242 ]), array([0.90236206, 0.68547212]), array([0.90156761, 0.74351728]), array([0.87014909, 0.65160904]), array([0.90812401, 0.69371368]), array([0.90924405, 0.74873321]), array([0.87383397, 0.80576566]), array([0.8904209 , 0.83368361]), array([0.90185467, 0.72123306]), array([0.91944965, 0.82825955]), array([0.89032375, 0.83425218]), array([0.89023273, 0.74886548]), array([0.90955153, 0.83212112]), array([0.90475271, 0.67772597]), array([0.92548976, 0.89073903]), array([0.89470977, 0.70598445]), array([0.89285563, 0.75052869]), array([0.82831774, 0.82059643]), array([0.87000487, 0.82244922]), array([0.8952393 , 0.85255268]), array([0.8831872 , 0.63257998]), array([0.89005835, 0.83766708]), array([0.90905711, 0.77725569]), array([0.91760562, 0.7497209 ]), array([0.89409791, 0.84307899]), array([0.89476989, 0.85798861])]\n","Mean per cat jaccard score: 0.8315088840626357\n"]}],"source":["sliced_images = '/content/gdrive/My Drive/crop_preprocessed_bai/test_2D'\n","pred_save_dir = '/content/gdrive/My Drive/pred_output/SDF'\n","pred_load_dir = '/content/gdrive/My Drive/pred_output/08-13_15-32'\n","ground_truth_dir = '/content/gdrive/My Drive/crop_preprocessed_bai/test_3D'\n","predicted = False\n","\n","# Get the current time\n","current_time = datetime.datetime.now()\n","time_string = current_time.strftime(\"%m-%d_%H-%M\")\n","\n","#create a new directory and name it with current time\n","if not predicted:\n","    pred_save_dir = os.path.join(pred_save_dir, time_string)\n","    os.makedirs(pred_save_dir, exist_ok=True)\n","\n","sliced_nii_files = glob.glob(os.path.join(sliced_images, \"*.nii.gz\"))\n","\n","\n","dice_scores = []\n","hausdorfs = []\n","per_catogory_jaccards = []\n","jaccards = []\n","\n","unet = model_load()\n","\n","#identify the evaluation matrix for the test samples\n","for sliced_nii_file in sliced_nii_files:\n","\n","    if not predicted:\n","        # print(\"if not predicted executed\")\n","        # Create the output filenames\n","        sample_name = os.path.basename(sliced_nii_file)\n","        pred_filename = os.path.join(pred_save_dir, \"pred\" + sample_name)\n","        # Load the 2D NIfTI file and returns nifti, numpy and sitk prediction\n","        # print(sliced_nii_file)\n","        pred_nifti, pred = mr_sdf_inference(unet, sliced_nii_file)\n","\n","        # pred = np.transpose(pred, (1, 2, 3, 0))\n","        # print(\"pred shape:\", pred.shape)\n","        # Save the predicted output as a NIfTI file\n","        nib.save(pred_nifti, pred_filename)\n","\n","        pred_sitk = sitk.ReadImage(pred_filename)\n","\n","        # pred = np.transpose(pred, (1, 2, 3, 0))\n","    else:\n","        # print(\"else executed\")\n","        sample_name = os.path.basename(sliced_nii_file)\n","        pred_filename = os.path.join(pred_load_dir, \"pred\" + sample_name)\n","        pred_nifti = nib.load(pred_filename)\n","        pred = pred_nifti.get_fdata()\n","        pred_sitk = sitk.ReadImage(pred_filename)\n","        pred = np.expand_dims(pred, axis=-1)\n","\n","    ground_truth_file = os.path.join(ground_truth_dir, sample_name)\n","    ground_truth = nib.load(ground_truth_file)\n","    # print(\"ground truth shape:\", ground_truth.shape)\n","    ground_truth_sitk = sitk.ReadImage(ground_truth_file)\n","\n","    ground_truth = ground_truth.get_fdata()\n","    num_labels = 3\n","\n","    #calculate the evaluation metrics and record them\n","    total_dice_score = dice_score(ground_truth, pred, num_labels)\n","    # print(total_dice_score)\n","    per_catogory_jaccard = []\n","    per_catogory_jaccard, jaccard = jaccard_score(ground_truth, pred)\n","    hausdorf_distance = hausdorf(ground_truth_sitk, pred_sitk)\n","    # per_category_accuracy, overall_acc = segmentation_accuracy(ground_truth, pred)\n","\n","    dice_scores.append(total_dice_score)\n","    hausdorfs.append(hausdorf_distance)\n","    per_catogory_jaccards.append(per_catogory_jaccard)\n","    jaccards.append(jaccard)\n","\n","\n","print(\"Dice scores:\", dice_scores)\n","mean_dice =  np.mean(dice_scores)\n","print(\"Mean Dice Score:\", mean_dice)\n","\n","print(\"Hausdorf distances:\", hausdorfs)\n","mean_haus =  np.mean(hausdorfs)\n","print(\"Mean Hausdorf distance:\", mean_haus)\n","\n","print(\"per cat accuracies:\", per_catogory_jaccards)\n","mean_cat_jac =  np.mean(per_catogory_jaccards)\n","print(\"Mean per cat jaccard score:\", mean_cat_jac)\n"]},{"cell_type":"markdown","metadata":{"id":"jW4Ee4NpyJCT"},"source":["# Save evaluation metrics as csv file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JAq0jwmgyQfN"},"outputs":[],"source":["import csv\n","# Path to the CSV file\n","csv_file_path = os.path.join(pred_save_dir, 'eva_metrics.csv')\n","\n","# Write the eva metrics to the CSV file\n","# Write the evaluation metrics to the CSV file\n","with open(csv_file_path, mode=\"w\", newline=\"\") as csv_file:\n","    writer = csv.writer(csv_file)\n","    header = [\"Dice Score\", \"Hausdorff Distance\"]\n","    max_categories = 2\n","    # Add per-category accuracy column headers\n","    for i in range(max_categories):\n","        header.append(f\"Category {i+1} Jaccard\")\n","\n","    header.append(\"Overall Accuracy\")\n","    writer.writerow(header)  # Write the header\n","\n","    for dice, hausdorff, category_jaccards, overall_jac in zip(dice_scores, hausdorfs, per_catogory_jaccards, jaccards):\n","        row = [dice, hausdorff]\n","\n","        # Fill in per-category accuracy values\n","        row.extend(category_jaccards)\n","\n","        # Fill in any remaining columns with None\n","        num_missing = max_categories - len(category_jaccards)\n","        row.extend([None] * num_missing)\n","\n","        row.append(overall_jac)\n","        writer.writerow(row)\n"]},{"cell_type":"markdown","source":["# Visualise tensorflow chart"],"metadata":{"id":"sKFPzmSZDuHR"}}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","toc_visible":true,"provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyMTKyd+qd8epotYxiFfY06g"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}