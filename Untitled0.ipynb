{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNOXRWG+xdFL+GFnyJfBTz0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"0jeyTB56xVBa"},"outputs":[],"source":["import numpy as np\n","import datetime as dt\n","\n","# Theano\n","import theano\n","import theano.tensor as tensor\n","from lib.config import cfg\n","\n","tensor5 = tensor.TensorType(theano.config.floatX, (False,) * 5)\n","\n","\n","class Net(object):\n","\n","    def __init__(self, random_seed=dt.datetime.now().microsecond, compute_grad=True):\n","        self.rng = np.random.RandomState(random_seed)\n","\n","        self.batch_size = cfg.CONST.BATCH_SIZE\n","        self.img_w = cfg.CONST.IMG_W\n","        self.img_h = cfg.CONST.IMG_H\n","        self.n_vox = cfg.CONST.N_VOX\n","        self.compute_grad = compute_grad\n","\n","        # (self.batch_size, 3, self.img_h, self.img_w),\n","        # override x and is_x_tensor4 when using multi-view network\n","        self.x = tensor.tensor4()\n","        self.is_x_tensor4 = True\n","\n","        # (self.batch_size, self.n_vox, 2, self.n_vox, self.n_vox),\n","        self.y = tensor5()\n","\n","        self.activations = []  # list of all intermediate activations\n","        self.loss = []  # final loss\n","        self.output = []  # final output\n","        self.error = []  # final output error\n","        self.params = []  # all learnable params\n","        self.grads = []  # will be filled out automatically\n","        self.setup()\n","\n","    def setup(self):\n","        self.network_definition()\n","        self.post_processing()\n","\n","    def network_definition(self):\n","        \"\"\" A child network must define\n","        self.loss\n","        self.error\n","        self.params\n","        self.output\n","        self.activations is optional\n","        \"\"\"\n","        raise NotImplementedError(\"Virtual Function\")\n","\n","    def add_layer(self, layer):\n","        raise NotImplementedError(\"TODO: add a layer\")\n","\n","    def post_processing(self):\n","        if self.compute_grad:\n","            self.grads = tensor.grad(self.loss, [param.val for param in self.params])\n","\n","    def save(self, filename):\n","        # params_cpu = {}\n","        params_cpu = []\n","        for param in self.params:\n","            # params_cpu[param.name] = np.array(param.val.get_value())\n","            params_cpu.append(param.val.get_value())\n","        np.save(filename, params_cpu)\n","        print('saving network parameters to ' + filename)\n","\n","    def load(self, filename, ignore_param=True):\n","        print('loading network parameters from ' + filename)\n","        params_cpu_file = np.load(filename)\n","        if filename.endswith('npz'):\n","            params_cpu = params_cpu_file[params_cpu_file.keys()[0]]\n","        else:\n","            params_cpu = params_cpu_file\n","\n","        succ_ind = 0\n","        for param_idx, param in enumerate(self.params):\n","            try:\n","                param.val.set_value(params_cpu[succ_ind])\n","                succ_ind += 1\n","            except IndexError:\n","                if ignore_param:\n","                    print('Ignore mismatch')\n","                else:\n","                    raise"]}]}